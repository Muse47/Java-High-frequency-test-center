# 数据库

[TOC]



## 1、mysql分页有什么优化

### 优化LIMIT分页

在系统中需要进行分页才做的时候，我们通常会使用LIMIT加上偏移量的办法实现，同时加上合适的ORDER BY字句。如果有对应的索引，通常效率会不错，否则，MySQL需要做大量的文件排序操作。

一个非常常见又令人头疼的问题就是，在偏移量非常大的时候（翻页到非常靠后的页面），例如可能是LIMIT  10000,20这样的查询，这时MySQL需要查询10020条记录然后只返回最后20条，前面10000条记录都被抛弃，这样的代价非常高。如果素所的页面被访问的频率都相同，那么这样的查询平均需要访问半个表的数据，要优化这种查询，要么在页面中限制分页的数量，要么是优化大偏移量的性能。

优化此类分页查询的一个最简单的办法就是尽可能地使用索引覆盖查询，而不是查询所有的列。然后根据需要做一个关联操作再返回所需的列。对于偏移量很大的时候，这样做的效率会提升很大。考虑下面的查询。

```
mysql> SELECT film_id, description FROM sakila.film ORDER BY title LIMIT 50, 5;
```

如果这张表非常大，那么这个查询最好改写成下面的样子：

```
mysql> SELECT film.film_id, film.description
    -> FROM sakila.film
    ->     INNER JOIN (
    ->         SELECT film_id FROM sakila.film
    ->         ORDER BY title LIMIT 50, 5
    ->     ) AS lim USING(film_id);
```

这里的“延迟关联”将大大提升查询效率，它让MySQL扫描尽可能的页面，获取需要访问的记录后再根据关联列回原表查询需要的所有列。这项技术也可以用于优化关联查询的LIMIT字句。

有时候也可以将LIMIT查询转换为已知位置的查询，让MySQL通过范围扫描获得到对应的结果。例如，如果在一个位置列上有索引，并且预先计算出了边界值，上面的查询就可以改写为：

```
mysql> SELECT film_id, description FROM sakila.film
    -> WHERE position BETWEEN 50 AND 54 ORDER BY position 
```

对数据进行排名的问题也与此类似，但往往还会和GROUP BY混合使用。在这种情况下通常需要预先计算并储存排名信息。

LIMIT和OFFSET的问题，它会导致MySQL扫描大量不需要的行然后再抛弃掉。如果可以使用书签记录上一次取数据的位置，那么下一次就可以直接从该书签的位置开始扫描，这样就可以避免使用OFFSET。例如，若需要按照租借记录做翻页，那么可以根据最新一条租借记录向后追溯，这种做法可行是因为租借记录的逐渐是单调增长的。首先使用下面的查询获取第一组结果：

```
mysql> SELECT * FROM sakila.rental
    -> ORDER BY rental_id DESC LIMIT 20;
```

该技术的好处是无论翻页到多么后面，其性能都会很好。

### 优化SQL_CALC_FOUND_ROWS

分页的时候，另一个常用的技巧是在LIMIT语句中加上SQL_CALC_FOUND_ROWS提示（hint),这样做可以获得去掉LIMIT以后满足条件的行数，因此可以作为分页的总数。看起来，MySQL做了一些非常高深的优化，像是通过某种方法预测了总行数。但实际上MySQL只有在扫描了所有满足条件的行，然后再抛弃掉不需要的行，而不是在满足LIMIT的行数后就终止扫描。所有该提示的代价可能非常高。(几年前本菜鸟在大学做项目的时候，就是用这个查询优化器的提示，以为这样会减少查询次数和扫描行数，后来我在工作后操作几百万行数的表的时候，这种方法性能很差)

一个更好的设计是将具体的页面换成“下一页”按钮，假设煤业显示20条记录，那么我们每次查询都是用LIMIT返回21条记录并只显示20条，如果第21条存在，那么我们就显示“下一页”按钮，否则就说明没有更多的数据，也就无需显示“下一页”按钮了。

一种做法是先获取并缓存较多的数据————例如，缓存1000条————然后每次分页都从这个缓存中获取。这样做可以让应用程序根据结果集的大小采取不同的策略，例如结果集少于1000，就可以在页面上显示所有的页面链接，因为数据都在缓存中，所以这样做性能不会有问题。如果结果集大于1000，则可以在页面上设计一个额外的“找到的结果多余1000条”之类的按钮。这两种策略都比每次生成全部结果集再抛弃掉不需要的数据的效率高很多。

有时候可以考虑使用EXPLAIN的结果集中的rows列的值作为结果集总数的近似值（实际上Google的搜索结果总数也是个近似值）。当需要精确结果的时候，在单独使用COUNT(*)来满足需求，这时如果能够使用索引覆盖扫描则通常会比SQL_CALC_FOUND_ROWS快得多。

## 2、悲观锁、乐观锁

### 悲观锁

悲观锁（Pessimistic Lock），顾名思义，就是很悲观，每次去拿数据的时候都认为别人会修改，所以每次在拿数据的时候都会上锁，这样别人想拿这个数据就会block直到它拿到锁。

悲观锁：假定会发生并发冲突，屏蔽一切可能违反数据完整性的操作。

Java synchronized 就属于悲观锁的一种实现，每次线程要修改数据时都先获得锁，保证同一时刻只有一个线程能操作数据，其他线程则会被block。

### 乐观锁

乐观锁（Optimistic Lock），顾名思义，就是很乐观，每次去拿数据的时候都认为别人不会修改，所以不会上锁，但是在提交更新的时候会判断一下在此期间别人有没有去更新这个数据。乐观锁适用于读多写少的应用场景，这样可以提高吞吐量。

乐观锁：假设不会发生并发冲突，只在提交操作时检查是否违反数据完整性。

乐观锁一般来说有以下2种方式：

1. 使用数据版本（Version）记录机制实现，这是乐观锁最常用的一种实现方式。何谓数据版本？即为数据增加一个版本标识，一般是通过为数据库表增加一个数字类型的 “version” 字段来实现。当读取数据时，将version字段的值一同读出，数据每更新一次，对此version值加一。当我们提交更新的时候，判断数据库表对应记录的当前版本信息与第一次取出来的version值进行比对，如果数据库表当前版本号与第一次取出来的version值相等，则予以更新，否则认为是过期数据。
2. 使用时间戳（timestamp）。乐观锁定的第二种实现方式和第一种差不多，同样是在需要乐观锁控制的table中增加一个字段，名称无所谓，字段类型使用时间戳（timestamp）, 和上面的version类似，也是在更新提交的时候检查当前数据库中数据的时间戳和自己更新前取到的时间戳进行对比，如果一致则OK，否则就是版本冲突。

Java JUC中的atomic包就是乐观锁的一种实现，AtomicInteger 通过CAS（Compare And Set）操作实现线程安全的自增。

### MySQL隐式和显示锁定

MySQL InnoDB采用的是两阶段锁定协议（two-phase locking protocol）。在事务执行过程中，随时都可以执行锁定，锁只有在执行 COMMIT或者ROLLBACK的时候才会释放，并且所有的锁是在同一时刻被释放。前面描述的锁定都是隐式锁定，InnoDB会根据事务隔离级别在需要的时候自动加锁。

另外，InnoDB也支持通过特定的语句进行显示锁定，这些语句不属于SQL规范：

- SELECT ... LOCK IN SHARE MODE
- SELECT ... FOR UPDATE

### 实战

接下来，我们通过一个具体案例来进行分析：考虑电商系统中的下单流程，商品的库存量是固定的，如何保证商品数量不超卖？ 其实需要保证数据一致性：某个人点击秒杀后系统中查出来的库存量和实际扣减库存时库存量的一致性就可以。

假设，MySQL数据库中商品库存表tb_product_stock 结构定义如下：

```
CREATE TABLE `tb_product_stock` (
  `id` bigint(20) NOT NULL AUTO_INCREMENT COMMENT '自增ID',
  `product_id` bigint(32) NOT NULL COMMENT '商品ID',
  `number` INT(8) NOT NULL DEFAULT 0 COMMENT '库存数量',
  `create_time` DATETIME NOT NULL COMMENT '创建时间',
  `modify_time` DATETIME NOT NULL COMMENT '更新时间',
  PRIMARY KEY (`id`),
  UNIQUE KEY `index_pid` (`product_id`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8 COMMENT='商品库存表';
```

对应的POJO类：

```
class ProductStock {
    private Long productId; //商品id
    private Integer number; //库存量

    public Long getProductId() {
        return productId;
    }

    public void setProductId(Long productId) {
        this.productId = productId;
    }

    public Integer getNumber() {
        return number;
    }

    public void setNumber(Integer number) {
        this.number = number;
    }
}
```

不考虑并发的情况下，更新库存代码如下：

```
    /**
     * 更新库存(不考虑并发)
     * @param productId
     * @return
     */
    public boolean updateStockRaw(Long productId){
        ProductStock product = query("SELECT * FROM tb_product_stock WHERE product_id=#{productId}", productId);
        if (product.getNumber() > 0) {
            int updateCnt = update("UPDATE tb_product_stock SET number=number-1 WHERE product_id=#{productId}", productId);
            if(updateCnt > 0){    //更新库存成功
                return true;
            }
        }
        return false;
    }
```

多线程并发情况下，会存在超卖的可能。

#### 悲观锁

```
/**
     * 更新库存(使用悲观锁)
     * @param productId
     * @return
     */
    public boolean updateStock(Long productId){
        //先锁定商品库存记录
        ProductStock product = query("SELECT * FROM tb_product_stock WHERE product_id=#{productId} FOR UPDATE", productId);
        if (product.getNumber() > 0) {
            int updateCnt = update("UPDATE tb_product_stock SET number=number-1 WHERE product_id=#{productId}", productId);
            if(updateCnt > 0){    //更新库存成功
                return true;
            }
        }
        return false;
    }
```

#### 乐观锁

```
    /**
     * 下单减库存
     * @param productId
     * @return
     */
    public boolean updateStock(Long productId){
        int updateCnt = 0;
        while (updateCnt == 0) {
            ProductStock product = query("SELECT * FROM tb_product_stock WHERE product_id=#{productId}", productId);
            if (product.getNumber() > 0) {
                updateCnt = update("UPDATE tb_product_stock SET number=number-1 WHERE product_id=#{productId} AND number=#{number}", productId, product.getNumber());
                if(updateCnt > 0){    //更新库存成功
                    return true;
                }
            } else {    //卖完啦
                return false;
            }
        }
        return false;
    }
```

使用乐观锁更新库存的时候不加锁，当提交更新时需要判断数据是否已经被修改（AND number=#{number}），只有在 number等于上一次查询到的number时 才提交更新。

** 注意** ：UPDATE 语句的WHERE 条件字句上需要建索引

### 乐观锁与悲观锁的区别

乐观锁的思路一般是表中增加版本字段，更新时where语句中增加版本的判断，算是一种CAS（Compare And Swep）操作，商品库存场景中number起到了版本控制（相当于version）的作用（ AND number=#{number}）。

悲观锁之所以是悲观，在于他认为本次操作会发生并发冲突，所以一开始就对商品加上锁（SELECT ... FOR UPDATE），然后就可以安心的做判断和更新，因为这时候不会有别人更新这条商品库存。

### 小结

这里我们通过 MySQL 乐观锁与悲观锁 解决并发更新库存的问题，当然还有其它解决方案，例如使用 **分布式锁**。目前常见分布式锁实现有两种：基于Redis和基于Zookeeper，基于这两种 业界也有开源的解决方案，例如 [Redisson Distributed locks ](https://link.jianshu.com?t=https://github.com/redisson/redisson/wiki/8.-distributed-locks-and-synchronizers)、 [Apache Curator Shared Lock ](https://link.jianshu.com?t=http://curator.apache.org/curator-recipes/shared-lock.html)，这里就不细说，网上Google 一下就有很多资料。

## 3、组合索引，最左原则

### **前言**

之前在网上看到过很多关于mysql联合索引最左前缀匹配的文章，自以为就了解了其原理，最近面试时和面试官交流，发现遗漏了些东西，这里自己整理一下这方面的内容。

------

### **最左前缀匹配原则**

在mysql建立联合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从联合索引的最左边开始匹配，示例：
对列col1、列col2和列col3建一个联合索引

```
KEY test_col1_col2_col3 on test(col1,col2,col3);
```

联合索引 test_col1_col2_col3 实际建立了(col1)、(col1,col2)、(col,col2,col3)三个索引。

```
SELECT * FROM test WHERE col1=“1” AND clo2=“2” AND clo4=“4”
```

上面这个查询语句执行时会依照最左前缀匹配原则，检索时会使用索引(col1,col2)进行数据匹配。

#### **注意**

索引的字段可以是任意顺序的，如：

```
SELECT * FROM test WHERE col1=“1” AND clo2=“2”
SELECT * FROM test WHERE col2=“2” AND clo1=“1”
```

这两个查询语句都会用到索引(col1,col2)，mysql创建联合索引的规则是首先会对联合合索引的最左边的，也就是第一个字段col1的数据进行排序，在第一个字段的排序基础上，然后再对后面第二个字段col2进行排序。其实就相当于实现了类似  order by col1 col2这样一种排序规则。

有人会疑惑第二个查询语句不符合最左前缀匹配：首先可以肯定是两个查询语句都包含索引(col1,col2)中的col1、col2两个字段，只是顺序不一样，查询条件一样，最后所查询的结果肯定是一样的。既然结果是一样的，到底以何种顺序的查询方式最好呢？此时我们可以借助mysql查询优化器explain，explain会纠正sql语句该以什么样的顺序执行效率最高，最后才生成真正的执行计划。

### **为什么要使用联合索引**

-  **减少开销**。建一个联合索引(col1,col2,col3)，实际相当于建了(col1),(col1,col2),(col1,col2,col3)三个索引。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！
-  **覆盖索引**。对联合索引(col1,col2,col3)，如果有如下的sql: select  col1,col2,col3 from test where col1=1 and  col2=2。那么MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。
-  **效率高**。索引列越多，通过索引筛选出的数据越少。有1000W条数据的表，有如下sql:select  *from table where col1=1 and col2=2 and col3=3,假设假设每个条件可以筛选出10%的数据，如果只有单值索引，那么通过该索引能筛选出1000W*10%=100w条数据，然后再回表从100w条数据中找到符合col2=2 and col3= 3的数据，然后再排序，再分页；如果是联合索引，通过索引筛选出1000w*10%* 10% *10%=1w，效率提升可想而知！

### **引申**

对于联合索引(col1,col2,col3)，查询语句SELECT * FROM test WHERE col2=2;是否能够触发索引？
大多数人都会说NO，实际上却是YES。
**原因**：

```
EXPLAIN SELECT * FROM test WHERE col2=2;
EXPLAIN SELECT * FROM test WHERE col1=1;
```

观察上述两个explain结果中的type字段。查询中分别是：

1. type: index
2. type: ref

**index**：这种类型表示mysql会对整个该索引进行扫描。要想用到这种类型的索引，对这个索引并无特别要求，只要是索引，或者某个**联合索引的一部分**，mysql都可能会采用index类型的方式扫描。但是呢，缺点是效率不高，mysql会从索引中的第一个数据一个个的查找到最后一个数据，直到找到符合判断条件的某个索引。所以，上述语句会触发索引。
**ref**：这种类型表示mysql会根据特定的算法快速查找到某个符合条件的索引，而不是会对索引中每一个数据都进行一一的扫描判断，也就是所谓你平常理解的使用索引查询会更快的取出数据。而要想实现这种查找，索引却是有要求的，要实现这种能快速查找的算法，索引就要满足特定的数据结构。简单说，**也就是索引字段的数据必须是有序的，才能实现这种类型的查找，才能利用到索引。**



## 4、mysql 的表锁、行锁

https://blog.csdn.net/mysteryhaohao/article/details/51669741



## 5、mysql 性能优化

### MySQL服务器逻辑架构

第一层，客户端/服务器。负责连接，授权，安全等。每个客户端连接都会在服务器拥有一个线程。解析器解析查询并创建解析树，然后优化（重写查询，选择索引等）节奏执行，select语句在解析之前先会先查询缓存若存在，直接返回结果。
第二层，核心服务。如查询解析，优化，缓存，内置函数，存储过程，触发器，视图…
第三层，存储引擎。负责数据存储和提取。

![这里写图片描述](https://img-blog.csdn.net/20170810140949379?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvcXFfMjk0MjM4ODM=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

### 事务

#### ACID

> 原子性（atomicity）:一个事务是不可分割的最小工作单元，要么全部提交成功，要么全部提交失败
> 一致性（consistency）:数据库总是从一个一致性的状态转换到另外一个一致性的状态。
> 隔离性（isolation）:一个事务所做的修改在最终提交之前，对其他事务不可见。
> 持久性（durability）:一旦事务提交，所做的修改就会永久保存到数据库中。
> 隔离级别
> 较低级别的隔离可以执行更高的并发，系统开销也低
> 未提交读（READ UNCOMMITTED）。事务中的修改，即使没有提交，其他事务都是可见的（脏读）。很少用。
> 提交读（READ COMMITTED）。事务从开始到提交之前，所做的修改对其他事务不可见。一般用。
> 可重复读（REPEATABLE READ）。MySQL默认的。
>
> 可串行化（SERIALIZABLE）。强制事务串行执行，最高隔离，行级加锁。很少用。

### Schema与数据类型优化

#### 优化数据类型

1.尽量使用可以正确存储数据的最小数据类型。原因：占用更少磁盘，内存，cup。
2.使用简单的。整型比字符操作代价低，原因：字符集和校队规则。
3.避免null。原因：可为null的列索引统计更复杂，更多存储空间，如果确实需要才使用。
4.时间类型。int 可以记录大范围的时间，datetime类型（范围1001-9999）适合用来记录数据的原始的创建时间，timestamp（范围1970-2038）类型适合用来记录数据的最后修改时间，只要修改记录，timestamp字段的值都会被自动更新。
5.小数类型。float和double近似小数，decimal精确小数，尽量只在对小数精确计算时使用，数据量大时使用bigint替代。
6.字符型。varchar可变长字符串适合长的字符串（需要额外的1或2个字节记录长度），char定长的，长度不够用空格填充，适合短的字符串及定值的如MD5值，或者经常变更的。
7.存储很大的字符串数据。使用blob（二进制方式）和text（字符方式，有排序规则和字符集），性能低下，尽量避免。
8.存储IPv4使用整型而不是varchar(15)，因为它实际就是32位无符号整数，加小数点只是方便阅读。
数据库设计注意
1.设计表非常宽，如果只有一小部分用到，转换代价就非常高，尽量避免。
2.太多关联。

### 索引优化

在MySQL中索引在存储引擎层，所以不同的存储引擎有不同的工作方式。一般情况都是指B-Tree索引，索引的优点:减少服务器需要扫描的数据量；帮助服务器避免排序和临时表；将随机I/O变为顺序I/O。
- Tree索引
  意味着索引的值都是按顺序存储的，之所以加快访问数据的速度，因为存储引擎不再需要全表扫描，而是从索引的根节点开始搜索。

- 哈希索引
基于哈希表实现，只有精确匹配索引所有列的查询才有效。冲突越多代价越大，只适用于特定场合，如url等。

    使用
    独立的列。是指索引列不能是表达式的一部分，也不能是函数的参数。
    前缀索引和索引选择性。如果索引需要很长的字符列，通常可以选择索引开始的部分字符，从而节约索引空间，提高效率，但会降低选择性。当然MySQL无法使用前缀索引做排序
    多列索引。在多个列上建立独立的单列索引大部分情况不能提高查询性能。MySQL可以使用索引合并策略
    选择合适的索引列顺序。当不需要考虑排序和分组时，将选择性最高的列放在前面，这时候索引的作用只是用于优化where条件的查找。
    聚族索引。它并不是一种索引类型，而是一种数据存储方式。表示数据行和相邻键值紧凑的存储在一起，故一个表只能有一个聚族索引。
    顺序主键。使用InnoDB尽可能的按主键顺序插入数据，尽可能使用单调增加的聚簇键的值插入新行，但对于高并发工作负载，会造成间隙锁竞争。
    覆盖索引。是指索引包含（覆盖）所有需要查询的字段的值。优秀的索引不应该只考虑到where条件，而应该考虑整个查询，因为MySQL的索引可以直接获取列的数据，这样就不需要读取数据行，回表查询。如果索引不能覆盖查询的所有列，或者查询中有like操作，那么索引将无法覆盖查询，这时候就需要重写查询

```
//重写前
select * from ta1  where a='**' and b like '**%';
//重写后
 select * from tal  
 join(
    select id from tal where a='**' b like '**%'
  ) as t2 on (t2.id=tal.id);
```

使用延迟关联，这样就能覆盖第一阶段的查询

> 重复索引，MySQL允许同一列上创建多个索引
>

```
create table test(
 id int not null primary key,
 a int not null,
 unique(id),
 index(id)
)
```



这样id上就有三个索引了，因为MySQL唯一和主键限制都是通过索引来实现的。

> 不用的索引。留着占位置，删除就好。

### 查询优化

- 查询的过程。客户端–服务端–解析–生成执行计划–执行–返回结果
- 不要查询不需要的记录。分页操作使用limit，而不是全部查出来再分页。
- 不能select * from …。
- 如果查询需要扫描大量的数据但只返回少数的行，可以使用索引覆盖扫描，或者使用单独的汇总表，或者重写查询。
- 拆分查询。一条复杂拆分成几条简单的查询
- 切分查询。比如一次删除10万行，切分成一次删除一万行。
- 分解关联查询。多表关联，可以对每一个表单查，将结果在应用程序中关联。
- MySQL优化器
- 重新定义关联表的顺序（即关联并不是按查询中指定的顺序）
- 将外连接转化为内连接
- 使用等价变换规则，合并和减少一些比较。
- 优化count min max
- 预估并转化为常数表达式。
- 覆盖索引扫描
- 子查询优化
- 提前终止查询。例如limit
- 等值传播
- 列表in()的比较。在MySQL中不等同于多个or条件，而是先将in中的数据先排序，然后通过二分查找来确定值是否满足条件。
- 优化器局限性
- in中有子查询如select * from A where id in(select id from B)。性能很糟，不建议使用
- MySQL关联查询
- 对任何关联都执行嵌套循环关联操作。
- 遇到子查询时，先执行并将结果放在临时表中；遇到右外连接时，会先改成等价的左外连接，故不能使用全外连接。
- MySQL不会生成查询字节码来执行，而是生成查询的一颗指令树，通过存储引擎执行并返回结果。
- 排序优化。排序是一个成本很高的操作，尽量避免。MySQL排序算法：单次传输排序（先读取查询所需要的所有列，再根据给定列排序，最后直接返回结果），再查询到第一条数据时就开始逐步返回。
- 对于关联子查询，尽可能使用左外连接代替。当然当返回结果只有一个表中的某些列的时候，关联查询会有重复结果集需要使用distinct，通常会产生中间表，这时候子查询可能更好。
- 最大值和最小值，mysql会做全表扫描。
- 在同一个表上查询和更新 
需求；查询tab表的总记录，并设置到id=4的col字段中

```
//错误写法
UPDATE tab set col=(
 select count(*) from lawyer_mediation
)
where id=4
```

```
//正确方法
update tab  INNER JOIN(
  select  count(*) cnt from tab 
) as der
set tab .col=der.cnt
where id =4
```

#### 优化count()

- count(*)用来行数，count(column)统计该列（值非空）数量。
- 当没有where时使用count（*）会非常快。
- 简单优化–

  1.需求如查找统计id>5的记录

```
//优化前
select count（*）from city where id>5;
//优化后,先查询小于等于5，再相减
select (select count(*) from city) - count(*) from city where id<=5
```

2.同一个查询中统计同一列的不同值的数量

```
//统计tab表中color为蓝和红的数量
select count(color='blue' or null)as blue,count(color='red' or null) as red from tab;
```

3.更复杂的应该考虑增加汇总表

#### 优化关联查询

1.确保on或者using字句中列上有索引，ON子句的语法格式为：table1.column_name = table2.column_name。
当当两个表采用了相同的命名列时，就可以使用 USING 来简化，格式为：USING(column_name)。
2.确保任何的group by 和order by的表达式只涉及到一个表中的列。
3.如果需要对关联查询做分组，并且按照表中的某个列分组，那么通常采用查找表的标识发列分组效率更高。select a ,count(*) from tab ... group by id

#### 优化limit分页

需求：对于偏移量很大的查询如limit 1000,10。会抛弃前面的大量记录会被抛弃，就需要优化.

```
-- 需要优化的sql
select id ,name from user order by phone limit 50,5
```

方案一：延迟关联

```
select lim.id ,name 
from user INNER JOIN(
select id from user order by phone limit 50,5
)as lim using(id)
```

分析：这里的延迟关联将大大提升查询效率，让MySQL扫描尽可能少的页面，获取需要访问的记录后再根据关联列回原表查询需要的所有列，也可以用于优化关联查询中的分页。

方案二：转换为已知位置查询

```
select id,name from user where position between 50 and 54 order by position;
```

分析：前提能够转换，该列上有索引，并且计算边界值，扫描更少的记录。
方案三：向前翻页

```
select id,name from user where id<10040 order by id desc limit 5
```

分析：前提是id主键是单调增长的。好处就是无论怎样往后翻页，性能都很好。

#### 实际问题优化

需求：计算两点之间的距离，如附近的人，附近的服务等功能。现有表tab和属性name,lat纬度,lon经度。

```
-- 计算公式
ACOS(
COS(latA)*COS(latB)*COS(lonA-lonB)
+SIN(latA)*SIN(latB)
)
```

这算是一个比较精确的计算公式了，但实际上没有必要，不仅消耗cup而且无法使用索引
优化：在表中添加两个列，lat_floor和lon_floor作为范围的近似值，并且在程序中计算出指定范围内的所有点的范围（经度，纬度的最大值和最小值）
如计算结果为

    --------------------------------------------------
    fl_lat | ce_lat | fl_lon | ce_lon
    -------------------------------------------------- 
    36		|40     |   -80  | -77
    --------------------------------------------------

通过范围来生成in()列表，作为where的字句

--不精确的查询

```
select * from tab
where lat between 38.03 - degrees(0.02) and 38.03 + degrees(0.02)
and lon between 78.48 - degrees(0.02) and 78.48 + degrees(0.02)
and lat_floor in(36,37,38,39,40) and lon_floor in(-80,-79,-78,-77)
```

当然，也可以使用前面的圆周公式精确计算，因为过滤了大量的数据，所有速度会很快。
3959是地球半径，radians是弧度

```
-- 根据毕达哥拉斯定理计算
select * from tab 
where lat_floor in(36,37,38,39,40) and lon_floor in(-80,-79,-78,-77)
and 3959*ACOS(
COS(RADIANS(lat)) * COS(RADIANS(38.03) * COS(RADIANS(lon)-RADIANS(-78.48))
+SIN(RADIANS(lat)) * SIN(RADIANS(38.03))
)<=100
```



#### 优化建议

1.限制结果集（行和列）
2.避免全表扫描，主要有在where子句中使用!= > <操作符，使用xx is null语句（使用默认值代替），使用or链接如...where a=1 or a=2 替换为...where a=1 union all ...where a=2；前置%,如...like '%a%';in 和not in(如果是连续的数值，可以用between and代替)；在where中使用表达式操作,..where num/2=100,可替换为num=100*2;在where子句中使用函数操作；
3.使用exists代替in
select n from a where n in(select n from b)替换为select n from a where exists(select 1 from b where n=a.n)

4.尽量使用数字型字段，在比较的时候只比较一次。



## 6、mysql的索引分类：B+，hash；什么情况用什么索引

备注：先说下，在MySQL文档里，实际上是把B+树索引写成了BTREE，例如像下面这样的写法：

    CREATE TABLE t(
      aid int unsigned not null auto_increment,
      userid int unsigned not null default 0,
      username varchar(20) not null default ‘’,
      detail varchar(255) not null default ‘’,
      primary key(aid),
      unique key(uid) USING BTREE,
      key (username(12)) USING BTREE — 此处 uname 列只创建了最左12个字符长度的部分索引
    )engine=InnoDB;

一个经典的BTREE索引数据结构见下图：

![](https://img-blog.csdn.net/20170104204305932)

### 1、B-Tree索引 

​    B-Tree 索引是 MySQL 数据库中使用最为频繁的索引类型，除了 Archive 存储引擎之外的其他所有的存储引擎都支持 B-Tree 索引。不仅仅在 MySQL 中是如此，实际上在其他的很多数据库管理系统中B-Tree 索引也同样是作为最主要的索引类型，这主要是因为B-Tree 索引的存储结构在数据库的数据检索中有非常优异的表现。 
​    一般来说， MySQL 中的 B-Tree 索引的物理文件大多都是以 Balance Tree 的结构来存储的，也就是所有实际需要的数据都存放于 Tree 的 Leaf Node ，而且到任何一个 Leaf Node 的最短路径的长度都是完全相同的，所以我们大家都称之为 B-Tree 索引当然，可能各种数据库（或 MySQL 的各种存储引擎）在存放自己的 B-Tree 索引的时候会对存储结构稍作改造。如 Innodb 存储引擎的 B-Tree 索引实际使用的存储结构实际上是 B+Tree ，也就是在 B-Tree 数据结构的基础上做了很小的改造，在每一个Leaf Node 上面出了存放索引键的相关信息之外，还存储了指向与该 Leaf Node 相邻的后一个 LeafNode 的指针信息，这主要是为了加快检索多个相邻 Leaf Node 的效率考虑。 
​    B+树是一个平衡的多叉树，从根节点到每个叶子节点的高度差值不超过1，而且同层级的节点间有指针相互链接。
​    在B+树上的常规检索，从根节点到叶子节点的搜索效率基本相当，不会出现大幅波动，而且基于索引的顺序扫描时，也可以利用双向指针快速左右移动，效率非常高。
​    因此，B+树索引被广泛应用于数据库、文件系统等场景。顺便说一下，xfs文件系统比ext3/ext4效率高很多的原因之一就是，它的文件及目录索引结构全部采用B+树索引，而ext3/ext4的文件目录结构则采用Linked list, hashed B-tree、Extents/Bitmap等索引数据结构，因此在高I/O压力下，其IOPS能力不如xfs。
详细可参见：
​    https://en.wikipedia.org/wiki/Ext4
​    https://en.wikipedia.org/wiki/XFS
​    在 Innodb 存储引擎中，存在两种不同形式的索引，一种是 Cluster 形式的主键索引（ Primary Key ），另外一种则是和其他存储引擎（如 MyISAM 存储引擎）存放形式基本相同的普通 B-Tree 索引，这种索引在 Innodb 存储引擎中被称为 Secondary Index。下面我们通过图示来针对这两种索引的存放 形式做一个比较。 

    图示中左边为 Clustered 形式存放的 Primary Key ，右侧则为普通的 B-Tree 索引。两种 Root Node 和 Branch Nodes 方面都还是完全一样的。而 Leaf Nodes 就出现差异了。在 Prim中， Leaf Nodes 存放的是表的实际数据，不仅仅包括主键字段的数据，还包括其他字段的数据据以主键值有序的排列。而 Secondary Index 则和其他普通的 B-Tree 索引没有太大的差异，Leaf Nodes 出了存放索引键 的相关信息外，还存放了 Innodb 的主键值。 
    所以，在 Innodb 中如果通过主键来访问数据效率是非常高的，而如果是通过 Secondary Index 来访问数据的话， Innodb 首先通过 Secondary Index 的相关信息，通过相应的索引键检索到 Leaf Node之后，需要再通过 Leaf Node 中存放的主键值再通过主键索引来获取相应的数据行。MyISAM 存储引擎的主键索引和非主键索引差别很小，只不过是主键索引的索引键是一个唯一且非空 的键而已。而且 MyISAM 存储引擎的索引和 Innodb 的 Secondary Index 的存储结构也基本相同，主要的区别只是 MyISAM 存储引擎在 Leaf Nodes 上面出了存放索引键信息之外，再存放能直接定位到 MyISAM 数据文件中相应的数据行的信息（如 Row Number ），但并不会存放主键的键值信息

### 2、hash索引

而哈希索引的示意图则是这样的：

![](https://img-blog.csdn.net/20170104204929966)


    Hash 索引结构的特殊性，其检索效率非常高，索引的检索可以一次定位，不像B-Tree 索引需要从根节点到枝节点，最后才能访问到页节点这样多次的IO访问，所以 Hash 索引的查询效率要远高于 B-Tree 索引。

   可能很多人又有疑问了，既然 Hash 索引的效率要比 B-Tree 高很多，为什么大家不都用 Hash 索引而还要使用 B-Tree 索引呢？任何事物都是有两面性的，Hash 索引也一样，虽然 Hash 索引效率高，但是 Hash 索引本身由于其特殊性也带来了很多限制和弊端，主要有以下这些。
  1).Hash 索引仅仅能满足"=","IN"和"<=>"查询，不能使用范围查询。
    由于 Hash 索引比较的是进行 Hash 运算之后的 Hash 值，所以它只能用于等值的过滤，不能用于基于范围的过滤，因为经过相应的 Hash 算法处理之后的 Hash 值的大小关系，并不能保证和Hash运算前完全一样。
  2).Hash 索引无法被用来避免数据的排序操作。
    由于 Hash 索引中存放的是经过 Hash 计算之后的 Hash 值，而且Hash值的大小关系并不一定和 Hash 运算前的键值完全一样，所以数据库无法利用索引的数据来避免任何排序运算；
  3).Hash 索引不能利用部分索引键查询。
    对于组合索引，Hash 索引在计算 Hash 值的时候是组合索引键合并后再一起计算 Hash 值，而不是单独计算 Hash 值，所以通过组合索引的前面一个或几个索引键进行查询的时候，Hash 索引也无法被利用。
  4).Hash 索引在任何时候都不能避免表扫描。
    前面已经知道，Hash 索引是将索引键通过 Hash 运算之后，将 Hash运算结果的 Hash 值和所对应的行指针信息存放于一个 Hash 表中，由于不同索引键存在相同 Hash 值，所以即使取满足某个 Hash 键值的数据的记录条数，也无法从 Hash 索引中直接完成查询，还是要通过访问表中的实际数据进行相应的比较，并得到相应的结果。
  5).Hash 索引遇到大量Hash值相等的情况后性能并不一定就会比B-Tree索引高。
    对于选择性比较低的索引键，如果创建 Hash 索引，那么将会存在大量记录指针信息存于同一个 Hash 值相关联。这样要定位某一条记录时就会非常麻烦，会浪费多次表数据的访问，而造成整体性能低下

     简单地说，哈希索引就是采用一定的哈希算法，把键值换算成新的哈希值，检索时不需要类似B+树那样从根节点到叶子节点逐级查找，只需一次哈希算法即可立刻定位到相应的位置，速度非常快。
从上面的图来看，B+树索引和哈希索引的明显区别是：
    1).如果是等值查询，那么哈希索引明显有绝对优势，因为只需要经过一次算法即可找到相应的键值；当然了，这个前提是，键值都是唯一的。如果键值不是唯一的，就需要先找到该键所在位置，然后再根据链表往后扫描，直到找到相应的数据；
    2).从示意图中也能看到，如果是范围查询检索，这时候哈希索引就毫无用武之地了，因为原先是有序的键值，经过哈希算法后，有可能变成不连续的了，就没办法再利用索引完成范围查询检索；
    3).同理，哈希索引也没办法利用索引完成排序，以及like ‘xxx%’ 这样的部分模糊查询（这种部分模糊查询，其实本质上也是范围查询）；
    4).哈希索引也不支持多列联合索引的最左匹配规则；
    5).B+树索引的关键字检索效率比较平均，不像B树那样波动幅度大，在有大量重复键值情况下，哈希索引的效率也是极低的，因为存在所谓的哈希碰撞问题。

    在MySQL中，只有HEAP/MEMORY引擎表才能显式支持哈希索引（NDB也支持，但这个不常用），InnoDB引擎的自适应哈希索引（adaptive hash index）不在此列，因为这不是创建索引时可指定的。
    还需要注意到：HEAP/MEMORY引擎表在mysql实例重启后，数据会丢失。
    通常，B+树索引结构适用于绝大多数场景，像下面这种场景用哈希索引才更有优势：
    在HEAP表中，如果存储的数据重复度很低（也就是说基数很大），对该列数据以等值查询为主，没有范围查询、没有排序的时候，特别适合采用哈希索引
例如这种SQL：
SELECT … FROM t WHERE C1 = ?; — 仅等值查询
在大多数场景下，都会有范围查询、排序、分组等查询特征，用B+树索引就可以了。



## 7、事务的特性和隔离级别

事务就是一组原子性的SQL语句，或者说一个独立的工作单元。事务内的SQL语句，要么全部执行成功，要么全部执行失败。
### 事务的四大特性（ACID）

原子性（atomicity）：一个事务必须视为一个不可分割的最小单元，整个事务中的所有操作要么全部提交成功，要么全部失败回滚，对于一个事务来说，不可能只执行成功其中的一部分操作，这就是事务的原子性。

一致性（consistency）：数据总是从一个一致性的状态转换到另一个一致性的状态。

隔离性（isolation）：一个事务所做的修改在最终提交以前，对其他事务是不可见的，多个并发事务之间是相互隔离的。关于事务的隔离性，MySQL提供了四种隔离级别。

持久性（durability）：一旦事务提交，所做的修改会永久保存到数据库中。即使系统崩溃，修改的数据也不会丢失。

### 不考虑隔离性可能产生的问题

现在重点说明下事务的隔离性，当多个线程（或多个客户端）都开启事务操作数据库中的数据时，数据库系统要能进行隔离操作，以保证各个线程获取数据的准确性。

如果不考虑事务的隔离性，会发生的几种问题：
2.1 脏读

脏读是指在一个事务处理过程中读取了另一个未提交的事务中的数据。
2.2 不可重复读

不可重复读是指对于数据库中的某个数据，一个事务内多次查询却返回了不同的数据值，这是由于在事务执行过程中，数据被另一个事务修改并提交了。
2.3 幻读

幻读是事务非独立执行时发生的一种现象。例如，事务T1对一个表中所有的行的某个字段做了从“1”修改为“2”的操作，这时事务T2又插入了一条新的记录，而该字段的值为“1”并且提交给数据库。这时，操作事务T1的用户如果再查看刚刚修改的数据，会发现还有一行没有修改，其实这行是从事务T2中添加的，就好像产生幻觉一样，这就是产生了幻读。

幻读和不可重复读都是读取了另一条已经提交的事务，所不同的是不可重复读查询的都是同一个数据项，而幻读针对的是一批数据（比如数据的个数）。
### 隔离级别

关于事务的隔离性，MySQL提供了四种隔离级别：

    Serializable（串行化）：可避免脏读、不可重复读、幻读的发生。（级别最高）
    Repeatable-read（可重复读）：可避免脏读、不可重复读的发生。
    Read-committed（读已提交）：可避免脏读的发生。
    Read-uncommitted（读未提交）：最低级别，任何情况都无法保证。（级别最低）

以上四种隔离级别最高的是Serializable，最低的是Read uncommitted级别。当然，隔离级别越高，执行效率就越低。

MySQL数据库中默认的隔离级别为Repeatable read。

像Serializable这样的级别，就是以锁表的方式（类似于Java多线程中的锁）使得其他的线程只能在锁外等待，选用哪一种隔离级别应该根据实际情况而定。

查看当前事务的隔离级别：

select @@tx_isolation;

临时设置事务的隔离级别：

    set transaction isolation level 隔离级别名称;
    或
    set tx_isolation=’隔离级别名称’;

注意： 设置数据库的隔离级别必须在开启事务之前！隔离级别的设置只对当前链接有效。