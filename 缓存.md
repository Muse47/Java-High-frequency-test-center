# 缓存

[TOC]



## 1、Redis用过哪些数据数据，以及Redis底层怎么实现

### 1、概述

------

##  

　　　　相信使用过Redis 的各位同学都很清楚，Redis 是一个基于键值对（key-value）的分布式存储系统，与Memcached类似，却优于Memcached的一个高性能的key-value数据库。

　　　　

　　　　在**《Redis设计与实现》**这样描述：

　　　　Redis 数据库里面的每个**键值对（key-value）** 都是由**对象（object）**组成的：

　　　　　　数据库键总是一个字符串对象（string object）;

　　　　　　数据库的值则可以是字符串对象、列表对象（list）、哈希对象（hash）、集合对象（set）、有序集合（sort set）对象这五种对象中的其中一种。

 

　　　　我们为什么会说Redis 优于Memcached 呢，因为Redis 的出现，丰富了memcached  中key-value的存储不足，在部分场合可以对关系数据库起到很好的补充作用，而且这些数据类型都支持push/pop、add/remove及取交集并集和差集及更丰富的操作，而且这些操作都是原子性的。

　　　　

　　　　我们今天探讨的并不是Redis 中value 的数据类型，而是他们的具体实现——**底层数据类型**。

　　　　**Redis** 底层数据结构有一下数据类型：

1. 1. 　**简单动态字符串**
   2.    **链表**
   3.    **字典**
   4.    **跳跃表**
   5.    **整数集合**
   6.    **压缩列表**
   7.    **对象**

　　　　　　　　　　

　　　　我们接下来会一步一步的探讨这些数据结构有什么特点，已经他们是如何构成我们所使用的value 数据类型。

 

### **2、简单动态字符串（simple dynamic string）SDS**

------

#### **2.1 概述**

　　　Redis 是一个开源的使用ANSI C语言编写的key-value 数据库，我们可能会较为主观的认为 Redis  中的字符串就是采用了C语言中的传统字符串表示，但其实不然，Redis  没有直接使用C语言传统的字符串表示，而是自己构建了一种名为简单动态字符串（simple dynamic string  SDS）的抽象类型，并将SDS用作Redis 的默认字符串表示：

```
redis>SET msg "hello world"
OK
```

　　　设置一个key= msg，value = hello world 的新键值对，他们底层是数据结构将会是：

　　　　　键（key）是一个字符串对象，对象的底层实现是一个保存着字符串“msg” 的SDS；

　　　　　值（value）也是一个字符串对象，对象的底层实现是一个保存着字符串“hello world” 的SDS

 

　　　从上述例子，我们可以很直观的看到我们在平常使用redis 的时候，创建的字符串到底是一个什么样子的数据类型。除了用来保存字符串以外，SDS还被用作缓冲区（buffer）AOF模块中的AOF缓冲区。

 

#### **2.2  SDS 的定义**

　　Redis 中定义动态字符串的结构：

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
/*  
 * 保存字符串对象的结构  
 */  
struct sdshdr {  
      
    // buf 中已占用空间的长度  
    int len;  
  
    // buf 中剩余可用空间的长度  
    int free;  
  
    // 数据空间  
    char buf[];  
};  
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

　　　![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161227201533132-1931479062.png)

 

　　　1、len 变量，用于记录buf 中已经使用的空间长度（这里指出Redis 的长度为5）

　　　2、free 变量，用于记录buf 中还空余的空间（初次分配空间，一般没有空余，在对字符串修改的时候，会有剩余空间出现）

　　   3、buf 字符数组，用于记录我们的字符串（记录Redis）

 

　

#### **2.3  SDS 与 C 字符串的区别**

　　　　传统的C 字符串 使用长度为N+1 的字符串数组来表示长度为N 的字符串，这样做在获取字符串长度，字符串扩展等操作的时候效率低下。C 语言使用这种简单的字符串表示方式，并不能满足Redis 对字符串在安全性、效率以及功能方面的要求

**2.3.1 获取字符串长度（SDS O（1）/C 字符串 O(n)）**

 　　　　传统的C 字符串 使用长度为N+1 的字符串数组来表示长度为N 的字符串，所以为了获取一个长度为C字符串的长度，必须遍历整个字符串。

　　　　 和C 字符串不同，SDS 的数据结构中，有专门用于保存字符串长度的变量，我们可以通过获取len 属性的值，直接知道字符串长度。

　　　　![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161227202606976-1847464022.png)

 

**2.3.2 杜绝缓冲区溢出**

　　　　**C 字符串** 不记录字符串长度，除了获取的时候复杂度高以外，还容易导致缓冲区溢出。

 　　　　假设程序中有两个在内存中紧邻着的 字符串 s1 和 s2，其中s1 保存了字符串“redis”，二s2 则保存了字符串“MongoDb”：

　　　　　　![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161227203105726-83486892.png)

　　　　 如果我们现在将s1 的内容修改为**redis cluster**，但是又忘了重新为s1 分配足够的空间，这时候就会出现以下问题：

　　　　　　![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161227203230523-893806723.png)

　　　　  我们可以看到，原本s2 中的内容已经被S1的内容给占领了，s2 现在为 cluster，而不是“Mongodb”。

 

　　　　 **Redis** 中SDS 的空间分配策略完全杜绝了发生缓冲区溢出的可能性：

　　　　 当我们需要对一个SDS 进行修改的时候，redis 会在执行拼接操作之前，预先检查给定SDS 空间是否足够，如果不够，会先拓展SDS 的空间，然后再执行拼接操作

![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161227203532039-1129846538.png)![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161227203537414-479762612.png)

 

 

**2.3.3 减少修改字符串时带来的内存重分配次数**　　　

　　C语言字符串在进行字符串的扩充和收缩的时候，都会面临着内存空间的重新分配问题。

　　　1. 字符串拼接会产生字符串的内存空间的扩充，在拼接的过程中，原来的字符串的大小很可能小于拼接后的字符串的大小，那么这样的话，就会导致一旦忘记申请分配空间，就会导致内存的溢出。

　　　2. 字符串在进行收缩的时候，内存空间会相应的收缩，而如果在进行字符串的切割的时候，没有对内存的空间进行一个重新分配，那么这部分多出来的空间就成为了内存泄露。

　　**举个例子：**我们需要对下面的SDS进行拓展，则需要进行空间的拓展，这时候redis 会将SDS的长度修改为13字节，并且将未使用空间同样修改为1字节 

　　![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161229194152929-2086423742.png)![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161229194202414-611382142.png)

　　　因为在上一次修改字符串的时候已经拓展了空间，再次进行修改字符串的时候会发现空间足够使用，因此无须进行空间拓展

　　![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161229194212726-505636956.png)

 

　　通过这种预分配策略，SDS将连续增长N次字符串所需的内存重分配次数从必定N次降低为最多N次

 

**2.3.4 惰性空间释放**

　　　　我们在观察SDS 的结构的时候可以看到里面的free  属性，是用于记录空余空间的。我们除了在拓展字符串的时候会使用到free 来进行记录空余空间以外，在对字符串进行收缩的时候，我们也可以使用free  属性来进行记录剩余空间，这样做的好处就是避免下次对字符串进行再次修改的时候，需要对字符串的空间进行拓展。

　　　　然而，我们并不是说不能释放SDS 中空余的空间，SDS 提供了相应的API，让我们可以在有需要的时候，自行释放SDS 的空余空间。

　　　　通过惰性空间释放，SDS 避免了缩短字符串时所需的内存重分配操作，并未将来可能有的增长操作提供了优化

 

 

**2.3.5 二进制安全**

　　　　C 字符串中的字符必须符合某种编码，并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，这些限制使得C字符串只能保存文本数据，而不能保存想图片，音频，视频，压缩文件这样的二进制数据。

　　　　但是在Redis中，不是靠空字符来判断字符串的结束的，而是通过len这个属性。那么，即便是中间出现了空字符对于SDS来说，读取该字符仍然是可以的。

　　　　例如：

 　　![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161229195615382-1745098995.png)

 

 

**2.3.6 兼容部分C字符串函数**

 　　　　虽然SDS 的API 都是二进制安全的，但他们一样遵循C字符串以空字符串结尾的惯例。

 

**2.3.7 总结**

 

| C 字符串                                   | SDS                                    |
| ------------------------------------------ | -------------------------------------- |
| 获取字符串长度的复杂度为O（N)              | 获取字符串长度的复杂度为O(1)           |
| API 是不安全的，可能会造成缓冲区溢出       | API 是安全的，不会造成缓冲区溢出       |
| 修改字符串长度N次必然需要执行N次内存重分配 | 修改字符串长度N次最多执行N次内存重分配 |
| 只能保存文本数据                           | 可以保存二进制数据和文本文数据         |
| 可以使用所有<String.h>库中的函数           | 可以使用一部分<string.h>库中的函数     |

 

　

### **3、链表**

------

 

 

#### **3.1 概述**

　　链表提供了高效的节点重排能力，以及顺序性的节点访问方式，并且可以通过增删节点来灵活地调整链表的长度。

　　链表在Redis 中的应用非常广泛，比如列表键的底层实现之一就是链表。当一个列表键包含了数量较多的元素，又或者列表中包含的元素都是比较长的字符串时，Redis 就会使用链表作为列表键的底层实现。

　　

#### **3.2 链表的数据结构**

　　　每个链表节点使用一个 **listNode**结构表示（adlist.h/listNode）：

```
typedef struct listNode{
      struct listNode *prev;
      struct listNode * next;
      void * value;  
}
```

 

　　　多个链表节点组成的双端链表：

　　![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161229201544382-398214447.png)

　　　　

 　　　　我们可以通过直接操作**list** 来操作链表会更加方便：

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
typedef struct list{
    //表头节点
    listNode  * head;
    //表尾节点
    listNode  * tail;
    //链表长度
    unsigned long len;
    //节点值复制函数
    void *(*dup) (void *ptr);
    //节点值释放函数
    void (*free) (void *ptr);
    //节点值对比函数
    int (*match)(void *ptr, void *key);
}
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 　　　　**list** 组成的结构图：

![img](https://images2015.cnblogs.com/blog/1053081/201612/1053081-20161229202122211-1253693576.png)

 

 

#### **3.3 链表的特性**

- **双端：链表节点带有prev 和next 指针，获取某个节点的前置节点和后置节点的时间复杂度都是O（N）**
- **无环：表头节点的 prev 指针和表尾节点的next 都指向NULL，对立案表的访问时以NULL为截止**
- **表头和表尾：因为链表带有head指针和tail 指针，程序获取链表头结点和尾节点的时间复杂度为O(1)**
- **长度计数器：链表中存有记录链表长度的属性 len**
- **多态：链表节点使用 void\* 指针来保存节点值，并且可以通过list 结构的dup 、 free、 match三个属性为节点值设置类型特定函数。**

 

 

### **4、字典**

 

------

　　

 

#### **4.1 概述**

 　　　字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对的抽象数据结构。　

　　　 在字典中，一个键（key）可以和一个值（value）进行关联，字典中的每个键都是独一无二的。在C语言中，并没有这种数据结构，但是**Redis 中构建了自己的字典实现**。

　　　 举个简单的例子：

```
redis > SET msg "hello world"
OK
```

　　　 创建这样的键值对（“msg”，“hello world”）在数据库中就是以字典的形式存储

 

 

#### **4.2 字典的定义**

##### 　　　**4.2.1 哈希表**

　　　Redis 字典所使用的哈希表由 dict.h/dictht 结构定义：

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
typedef struct dictht {
   //哈希表数组
   dictEntry **table;
   //哈希表大小
   unsigned long size;

   //哈希表大小掩码，用于计算索引值
   unsigned long sizemask;
   //该哈希表已有节点的数量
   unsigned long used;
}
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

　　　一个空的字典的结构图如下：

![img](https://images2015.cnblogs.com/blog/1053081/201701/1053081-20170102210846237-1704622314.png)

　　　我们可以看到，在结构中存有指向dictEntry 数组的指针，而我们用来存储数据的空间既是dictEntry

#####          4.2.2 哈希表节点（ dictEntry ）

　　　dictEntry 结构定义：

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
typeof struct dictEntry{
   //键
   void *key;
   //值
   union{
      void *val;
      uint64_tu64;
      int64_ts64;
   }   struct dictEntry *next;

}
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

　　　在数据结构中，我们清楚key 是唯一的，但是我们存入里面的key 并不是直接的字符串，而是一个hash 值，通过hash 算法，将字符串转换成对应的hash 值，然后在dictEntry 中找到对应的位置。

​        这时候我们会发现一个问题，如果出现hash 值相同的情况怎么办？Redis 采用了**链地址法：**

　　　**![img](https://images2015.cnblogs.com/blog/1053081/201701/1053081-20170102211529441-654290925.png)**

　　　当k1 和k0 的hash 值相同时，将k1中的next 指向k0 想成一个链表。

 

##### 　　　4.2.3 字典

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
typedef struct dict {    // 类型特定函数
    dictType *type;    // 私有数据
    void *privedata;    // 哈希表
    dictht  ht[2];
    // rehash 索引
    in trehashidx;

}
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

 

　　　　type 属性 和privdata 属性是针对不同类型的键值对，为创建多态字典而设置的。

　　　　ht 属性是一个包含两个项（两个哈希表）的数组

　　　　普通状态下的字典：

![img](https://images2015.cnblogs.com/blog/1053081/201701/1053081-20170102212225862-973112494.png)

　　

 

 

#### **4.3 解决哈希冲突**

 　　在上述分析哈希节点的时候我们有讲到：在插入一条新的数据时，会进行哈希值的计算，如果出现了hash值相同的情况，Redis  中采用了连地址法（separate chaining）来解决键冲突。每个哈希表节点都有一个next 指针，多个哈希表节点可以使用next  构成一个单向链表，被分配到同一个索引上的多个节点可以使用这个单向链表连接起来解决hash值冲突的问题。

　　举个例子：

　　现在哈希表中有以下的数据：k0 和k1

![img](https://images2015.cnblogs.com/blog/1053081/201701/1053081-20170102213019237-882199384.png)

　　  我们现在要插入k2，通过hash 算法计算到k2 的hash 值为2，即我们需要将k2 插入到dictEntry[2]中：

　　　 ![img](https://images2015.cnblogs.com/blog/1053081/201701/1053081-20170102213126769-1011081442.png)

　　   在插入后我们可以看到，dictEntry指向了k2，k2的next 指向了k1，从而完成了一次插入操作（这里选择表头插入是因为哈希表节点中没有记录链表尾节点位置）

 

 

#### **4.4 Rehash**

　　随着对哈希表的不断操作，哈希表保存的键值对会逐渐的发生改变，为了让哈希表的负载因子维持在一个合理的范围之内，我们需要对哈希表的大小进行相应的扩展或者压缩，这时候，我们可以通过 rehash（重新散列）操作来完成。

 

##### 　　**4.4.1 目前的哈希表状态：**

　　　　我们可以看到，哈希表中的每个节点都已经使用到了，这时候我们需要对哈希表进行拓展。

![img](https://images2015.cnblogs.com/blog/1053081/201701/1053081-20170102213822316-795162750.png)

　　

##### 　　**4.4.2 为哈希表分配空间**

　　　　哈希表空间分配规则：

　　　　　　如果执行的是拓展操作，那么ht[1] 的大小为第一个大于等于ht[0] 的2的n次幂

　　　　　　如果执行的是收缩操作，那么ht[1] 的大小为第一个大于等于ht[0] 的2的n次幂

　　　　因此这里我们为ht[1] 分配 空间为8，

　　![img](https://images2015.cnblogs.com/blog/1053081/201701/1053081-20170102213924144-1854942861.png)

 

##### 　　**4.4.3 数据转移**

　　　　将ht[0]中的数据转移到ht[1]中，在转移的过程中，需要对哈希表节点的数据重新进行哈希值计算

　　　　数据转移后的结果：

　　![img](https://images2015.cnblogs.com/blog/1053081/201701/1053081-20170102214334769-1157973551.png)

 

#####  　　**4.4.4 释放ht[0]**

　　　　将ht[0]释放，然后将ht[1]设置成ht[0]，最后为ht[1]分配一个空白哈希表：

　　![img](https://images2015.cnblogs.com/blog/1053081/201701/1053081-20170102214455034-353712227.png)

 

##### 　　**4.4.5 渐进式 rehash**

　　　　上面我们说到，在进行拓展或者压缩的时候，可以直接将所有的键值对rehash 到ht[1]中，这是因为数据量比较小。在实际开发过程中，这个rehash 操作并不是一次性、集中式完成的，而是分多次、渐进式地完成的。

　　　　渐进式rehash 的详细步骤：

　　　　　　1、为ht[1] 分配空间，让字典同时持有ht[0]和ht[1]两个哈希表

　　　　　　2、在几点钟维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash 开始

　　　　　　3、在rehash 进行期间，每次对字典执行CRUD操作时，程序除了执行指定的操作以外，还会将ht[0]中的数据rehash 到ht[1]表中，并且将rehashidx加一

　　　　　　4、当ht[0]中所有数据转移到ht[1]中时，将rehashidx 设置成-1，表示rehash 结束

　　　　

　　　　采用渐进式rehash 的好处在于它采取分而治之的方式，避免了集中式rehash 带来的庞大计算量。

##  2、Redis缓存穿透，缓存雪崩

### 前言

设计一个缓存系统，不得不要考虑的问题就是：缓存穿透、缓存击穿与失效时的雪崩效应。

### 缓存穿透

缓存穿透是指查询一个一定不存在的数据，由于缓存是不命中时被动写的，并且出于容错考虑，如果从存储层查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到存储层去查询，失去了缓存的意义。在流量大时，可能DB就挂掉了，要是有人利用不存在的key频繁攻击我们的应用，这就是漏洞。

#### 解决方案

有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器，将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被 这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。另外也有一个更为简单粗暴的方法（我们采用的就是这种），如果一个查询返回的数据为空（不管是数 据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

### 缓存雪崩

缓存雪崩是指在我们设置缓存时采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部转发到DB，DB瞬时压力过重雪崩。

#### 解决方案

缓存失效时的雪崩效应对底层系统的冲击非常可怕。大多数系统设计者考虑用加锁或者队列的方式保证缓存的单线 程（进程）写，从而避免失效时大量的并发请求落到底层存储系统上。这里分享一个简单方案就时讲缓存失效时间分散开，比如我们可以在原有的失效时间基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效的事件。

### 缓存击穿

对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发地访问，是一种非常“热点”的数据。这个时候，需要考虑一个问题：缓存被“击穿”的问题，这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。

缓存在某个时间点过期的时候，恰好在这个时间点对这个Key有大量的并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。

#### 解决方案

##### 1.使用互斥锁(mutex5 key)

业界比较常用的做法，是使用mutex。简单地来说，就是在缓存失效的时候（判断拿出来的值为空），不是立即去load db，而是先使用缓存工具的某些带成功操作返回值的操作（比如Redis的SETNX或者Memcache的ADD）去set一个mutex key，当操作返回成功时，再进行load db的操作并回设缓存；否则，就重试整个get缓存的方法。

SETNX，是「SET if Not eXists」的缩写，也就是只有不存在的时候才设置，可以利用它来实现锁的效果。在redis2.6.1之前版本未实现setnx的过期时间，所以这里给出两种版本代码参考：

    //2.6.1前单机版本锁
    String get(String key) {  
       String value = redis.get(key);  
       if (value  == null) {  
        if (redis.setnx(key_mutex, "1")) {  
            // 3 min timeout to avoid mutex holder crash  
            redis.expire(key_mutex, 3 * 60)  
            value = db.get(key);  
            redis.set(key, value);  
            redis.delete(key_mutex);  
        } else {  
            //其他线程休息50毫秒后重试  
            Thread.sleep(50);  
            get(key);  
        }  
      }  
    }

最新版本代码：

    public String get(key) {
          String value = redis.get(key);
          if (value == null) { //代表缓存值过期
              //设置3min的超时，防止del操作失败的时候，下次缓存过期一直不能load db
    		  if (redis.setnx(key_mutex, 1, 3 * 60) == 1) {  //代表设置成功
                   value = db.get(key);
                          redis.set(key, value, expire_secs);
                          redis.del(key_mutex);
                  } else {  //这个时候代表同时候的其他线程已经load db并回设到缓存了，这时候重试获取缓存值即可
                          sleep(50);
                          get(key);  //重试
                  }
              } else {
                  return value;      
              }
     }

memcache代码：

    if (memcache.get(key) == null) {  
        // 3 min timeout to avoid mutex holder crash  
        if (memcache.add(key_mutex, 3 * 60 * 1000) == true) {  
            value = db.get(key);  
            memcache.set(key, value);  
            memcache.delete(key_mutex);  
        } else {  
            sleep(50);  
            retry();  
        }  
    } 

##### 2."提前"使用互斥锁(mutex key)：

在value内部设置1个超时值(timeout1), timeout1比实际的memcache timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。伪代码如下：

    v = memcache.get(key);  
    if (v == null) {  
        if (memcache.add(key_mutex, 3 * 60 * 1000) == true) {  
            value = db.get(key);  
            memcache.set(key, value);  
            memcache.delete(key_mutex);  
        } else {  
            sleep(50);  
            retry();  
        }  
    } else {  
        if (v.timeout <= now()) {  
            if (memcache.add(key_mutex, 3 * 60 * 1000) == true) {  
                // extend the timeout for other threads  
                v.timeout += 3 * 60 * 1000;  
                memcache.set(key, v, KEY_TIMEOUT * 2);  
      
                // load the latest value from db  
                v = db.get(key);  
                v.timeout = KEY_TIMEOUT;  
                memcache.set(key, value, KEY_TIMEOUT * 2);  
                memcache.delete(key_mutex);  
            } else {  
                sleep(50);  
                retry();  
            }  
        }  
    } 

##### 3."永远不过期"：  

这里的“永远不过期”包含两层意思：

    (1) 从redis上看，确实没有设置过期时间，这就保证了，不会出现热点key过期问题，也就是“物理”不过期。
    
    (2) 从功能上看，如果不过期，那不就成静态的了吗？所以我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，也就是“逻辑”过期
    
        从实战看，这种方法对于性能非常友好，唯一不足的就是构建缓存时候，其余线程(非构建缓存的线程)可能访问的是老数据，但是对于一般的互联网功能来说这个还是可以忍受。
    
    String get(final String key) {  
            V v = redis.get(key);  
            String value = v.getValue();  
            long timeout = v.getTimeout();  
            if (v.timeout <= System.currentTimeMillis()) {  
                // 异步更新后台异常执行  
                threadPool.execute(new Runnable() {  
                    public void run() {  
                        String keyMutex = "mutex:" + key;  
                        if (redis.setnx(keyMutex, "1")) {  
                            // 3 min timeout to avoid mutex holder crash  
                            redis.expire(keyMutex, 3 * 60);  
                            String dbValue = db.get(key);  
                            redis.set(key, dbValue);  
                            redis.delete(keyMutex);  
                        }  
                    }  
                });  
            }  
            return value;  
    }

##### 4.资源保护：

采用netflix的hystrix，可以做资源的隔离保护主线程池，如果把这个应用到缓存的构建也未尝不可。

四种解决方案：没有最佳只有最合适

![1563361656588](C:\Users\Muse47\AppData\Roaming\Typora\typora-user-images\1563361656588.png)

### 总结

针对业务系统，永远都是具体情况具体分析，没有最好，只有最合适。

最后，对于缓存系统常见的缓存满了和数据丢失问题，需要根据具体业务分析，通常我们采用LRU策略处理溢出，Redis的RDB和AOF持久化策略来保证一定情况下的数据安全。

##  3、如何使用Redis来实现分布式锁

在我写这篇文章的时候，其实我还是挺纠结的，因为我这个方案本身也是雕虫小技拿出来显眼肯定会被贻笑大方，但是我最终还是拿出来与大家分享，我本着学习的态度和精神，希望大家能够给与我指导和改进方案。

> **一、关于分布式锁**

关于分布式锁，可能绝大部分人都会或多或少涉及到。 我举二个例子：
 **场景一：**从前端界面发起一笔支付请求，如果前端没有做防重处理，那么可能在某一个时刻会有二笔一样的单子同时到达系统后台。

**场景二：**在App中下订单的时候，点击确认之后，没反应，就又点击了几次。在这种情况下，如果无法保证该接口的幂等性，那么将会出现重复下单问题。 在接收消息的时候，消息推送重复。如果处理消息的接口无法保证幂等，那么重复消费消息产生的影响可能会非常大。

类似这种场景，我们有很多种方法，可以使用幂等操作，也可以使用锁的操作。
 **我们先来解释一下什么是幂等操作：** 所谓幂等，简单地说，就是对接口的多次调用所产生的结果和调用一次是一致的。扩展一下，这里的接口，可以理解为对外发布的HTTP接口或者Thrift接口，也可以是接收消息的内部接口，甚至是一个内部方法或操作。

在分布式环境中，网络环境更加复杂， 因前端操作抖动、网络故障、消息重复、响应速度慢等原因，对接口的重复调用概率会比集中式环境下更大，尤其是重复消息在分布式环境中很难避免。Tyler Treat也在《You Cannot Have Exactly-Once Delivery》一文中提到：
 Within the context of a distributed system, you cannot have exactly-once message delivery.

分布式环境中，有些接口是天然保证幂等性的，如查询操作。有些对数据的修改是一个常量，并且无其他记录和操作，那也可以说是具有幂等性的。其他情况下，所有涉及对数据的修改、状态的变更就都有必要防止重复性操作的发生。通过间接的实现接口的幂等性来防止重复操作所带来的影响，成为了一种有效的解决方案。

于是我们根据以上内容就可以讲一下使用分布式锁的方法有哪些。

1、使用数据库乐观锁，包括主键防重，版本号控制。但是这两种方法各有利弊。

- 使用主键冲突的策略进行防重，在并发量非常高的情况下对数据库性能会有影响，尤其是应用数据表和主键冲突表在一个库的时候，表现更加明显。其实针对是否会对数据库性能产生影响这个话题，我也和一些专业的DBA同学讨论过，普遍认可的是在mysql数据库中采用主键冲突防重，在大并发情况下有可能会造成锁表现象，比较好的办法是在程序中生产主键进行防重。
- 使用版本号策略
   这个策略源于mysql的mvcc机制，使用这个策略其实本身没有什么问题，唯一的问题就是对数据表侵入较大，我们要为每个表设计一个版本号字段，然后写一条判断sql每次进行判断。

2、Zookeeper防重策略
 利用ZK确实是一个不错的方案，流程如下：



![img](https:////upload-images.jianshu.io/upload_images/1049928-5e617f14e83478f7.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/463)



以前的版本中普遍传言说它的性能不好，但是后续的版本性能得到了较大提高，经过系统压测还是能够支撑较大并发量的，经过压测三台Zookeeper能搞住20000tps。
 用zookeeper的优点大概有：高可用、公平锁、心跳保持锁。

3、Redis防重策略
 关于主从Redis方案最简单的实现流程如下：



![img](https:////upload-images.jianshu.io/upload_images/1049928-d4a0497ab2846174.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/852)

表面来看，这个方案似乎很管用，但是这里存在一个问题：在我们的系统架构里存在一个单点故障，如果Redis的master节点宕机了怎么办呢？有人可能会说：加一个slave节点！在master宕机时用slave就行了！但是其实这个方案明显是不可行的，因为这种方案无法保证第1个安全互斥属性，因为Redis的复制是异步的。 总的来说，这个方案里有一个明显的竞争条件（race condition），举例来说：

- 客户端A在master节点拿到了锁。
- master节点在把A创建的key写入slave之前宕机了。
- slave变成了master节点
- B也得到了和A还持有的相同的锁（因为原来的slave里还没有A持有锁的信息）

**于是我就在想，我该如何做才能让Redis在分布式锁这一块能够达到高可用呢？**
 于是基于Tedis的思想（[http://www.oschina.net/p/tedis](https://link.jianshu.com?t=http://www.oschina.net/p/tedis)）    我自己写了一套针对分布式锁的双写Redis框架。

> **二、双写Redis的架构图**





![img](https:////upload-images.jianshu.io/upload_images/1049928-45412948771701f3.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/711)


**说明：** 组件名叫YeeRedisGroup，基本服务主要有四个，当数据到来的时候，会分别插入二个Redis服务，这二个Redis服务采用的是异地双活的方案，当其中一个Redis服务挂了以后，会将这个Redis服务从可用队列中摘除，放入重试队列中，另一个Redis则会继续使用。同样读取Redis的时候只会从可用队列中读取第一个Redis服务继续读取。

> **三、双写Redis的类图结构**





![img](https:////upload-images.jianshu.io/upload_images/1049928-49caa3a7f8e32578.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/831)




**说明：**



> **四、双写Redis的时序图**






![img](https:////upload-images.jianshu.io/upload_images/1049928-7613d5c596d3d361.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1000)


**说明：**



> **五、故障容错流程图**



![img](https:////upload-images.jianshu.io/upload_images/1049928-5d941bec6b35789a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/530)

> **六、故障重试流程图**



![img](https:////upload-images.jianshu.io/upload_images/1049928-f43b1921212f4299.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/552)

> **七、主动通知与主动查询流程图**



![img](https:////upload-images.jianshu.io/upload_images/1049928-888b7529ccedfbb9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/580)

> **八、Redis 可用队列与重试队列结构图**



![img](https:////upload-images.jianshu.io/upload_images/1049928-f03033932b17ca69.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/671)

> **九、项目阐述**

上面项目的最终压测结果还没有出来，并且项目也还没有最终开源，在此我是非常想和大家进行交流，我觉得可能的缺点是客户端相对比较重，有大量的逻辑都在客户端上面进行，从我个人是本着交流与学习的态度勇于接受各种批评与指正，谢谢。



##  4、Redis的并发竞争问题如何解决

### **需求由来**

#### **1.Redis高并发的问题**

Redis缓存的高性能有目共睹，应用的场景也是非常广泛，但是在高并发的场景下，也会出现问题：缓存击穿、缓存雪崩、缓存和数据一致性，以及今天要谈到的缓存并发竞争。

这里的并发指的是多个redis的client同时set key引起的并发问题。

#### **2.出现并发设置Key的原因**

Redis是一种单线程机制的nosql数据库，基于key-value，数据可持久化落盘。由于单线程所以Redis本身并没有锁的概念，多个客户端连接并不存在竞争关系，但是利用jedis等客户端对Redis进行并发访问时会出现问题。

比如：同时有多个子系统去set一个key。这个时候要注意什么呢？

#### **3.举一个例子**

多客户端同时并发写一个key，一个key的值是1，本来按顺序修改为2,3,4，最后是4，但是顺序变成了4,3,2，最后变成了2。

![高并发架构系列：Redis并发竞争key的解决方案详解](https://oscimg.oschina.net/oscnet/a0dc1b7fa26a4695978986ca8ab900f5.)

 

如何解决redis的并发竞争key问题呢？下面给到**2个Redis并发竞争的解决方案。**



### **第一种方案：分布式锁+时间戳**

#### **1.整体技术方案**

这种情况，主要是准备一个分布式锁，大家去抢锁，抢到锁就做set操作。

加锁的目的实际上就是把并行读写改成串行读写的方式，从而来避免资源竞争。

#### **2.Redis分布式锁的实现**

主要用到的redis函数是setnx()

#### **用SETNX实现分布式锁**

利用SETNX非常简单地实现分布式锁。例如：某客户端要获得一个名字youzhi的锁，客户端使用下面的命令进行获取：

SETNX lock.youzhi<current Unix time + lock timeout + 1>

- 如返回1，则该客户端获得锁，把lock.youzhi的键值设置为时间值表示该键已被锁定，该客户端最后可以通过DEL lock.foo来释放该锁。
- 如返回0，表明该锁已被其他客户端取得，这时我们可以先返回或进行重试等对方完成或等待锁超时。

#### **2.时间戳**

由于上面举的例子，要求key的操作需要顺序执行，所以需要保存一个时间戳判断set顺序。

> 系统A key 1 {ValueA 7:00}
>
> 系统B key 1 { ValueB 7:05}

假设系统B先抢到锁，将key1设置为{ValueB 7:05}。接下来系统A抢到锁，发现自己的key1的时间戳早于缓存中的时间戳（7:00<7:05），那就不做set操作了。

#### **3.什么是分布式锁**

因为传统的加锁的做法（如java的synchronized和Lock）这里没用，只适合单点。因为这是分布式环境，需要的是分布式锁。

当然，分布式锁可以基于很多种方式实现，比如zookeeper、redis等，不管哪种方式实现，基本原理是不变的：用一个状态值表示锁，对锁的占用和释放通过状态值来标识。



### **第二种方案：利用消息队列**

在并发量过大的情况下,可以通过消息中间件进行处理,把并行读写进行串行化。

把Redis.set操作放在队列中使其串行化,必须的一个一个执行。

这种方式在一些高并发的场景中算是一种通用的解决方案。





以上就是Redis并发竞争key技术方案详解，相关的Redis高并发问题具体还可以参考我的往期博文：

《高并发架构系列：如何解决Redis雪崩、穿透、并发等5大难题》

##  5、Redis持久化的几种方式，优缺点是什么，怎么实现的

[Redis](http://lib.csdn.net/base/redis)是一个支持持久化的内存[数据库](http://lib.csdn.net/base/mysql)，也就是说redis需要经常将内存中的数据同步到磁盘来保证持久化。redis支持四种持久化方式，一是 Snapshotting（快照）也是默认方式；二是Append-only  file（缩写aof）的方式；三是虚拟内存方式；四是diskstore方式。下面分别介绍之。



### **（一）Snapshotting**

​       快照是默认的持久化方式。这种方式是就是将内存中数据以快照的方式写入到二进制文件中,默认的文件名为dump.rdb。可以通过配置设置自动做快照持久化的方式。我们可以配置redis在n秒内如果超过m个key被修改就自动做快照，下面是默认的快照保存配置：



    save 900 1  #900秒内如果超过1个key被修改，则发起快照保存
    save 300 10 #300秒内容如超过10个key被修改，则发起快照保存
    save 60 10000
快照保存过程：

​       \1. redis调用fork,现在有了子进程和父进程。
​       \2. 父进程继续处理client请求，子进程负责将内存内容写入到临时文件。由于os的写时复制机制（copy  on write)父子进程会共享相同的物理页面，当父进程处理写请求时os会为父进程要修改的页面创建副本，而不是写共享的页面。所以子进程的地址空间内的数据是fork时刻整个数据库的一个快照。
​       \3. 当子进程将快照写入临时文件完毕后，用临时文件替换原来的快照文件，然后子进程退出（fork一个进程入内在也被复制了，即内存会是原来的两倍）。

​       client 也可以使用save或者bgsave命令通知redis做一次快照持久化。save操作是在主线程中保存快照的，由于redis是用一个主线程来处理所有 client的请求，这种方式会阻塞所有client请求。所以不推荐使用。**另一点需要注意的是，每次快照持久化都是将内存数据完整写入到磁盘一次，并不是增量的只同步脏数据。如果数据量大的话，而且写操作比较多，必然会引起大量的磁盘io****操作，可能会严重影响性能。**       另外由于快照方式是在一定间隔时间做一次的，所以如果redis意外down掉的话，就会丢失最后一次快照后的所有修改。如果应用要求不能丢失任何修改的话，可以采用aof持久化方式。下面介绍：



### **（二）Append-only file**

aof 比快照方式有更好的持久化性，是由于在使用**aof持久化方式时，redis会将每一个收到的写命令都通过write函数追加到文件中(默认是appendonly.aof)。当redis重启时会通过重新执行文件中保存的写命令来在内存中重建整个数据库的内容。**当然由于os会在内核中缓存 write做的修改，所以可能不是立即写到磁盘上。这样aof方式的持久化也还是有可能会丢失部分修改。不过我们可以通过配置文件告诉redis我们想要通过fsync函数强制os写入到磁盘的时机。有三种方式如下（默认是：每秒fsync一次）：



    appendonly yes   #启用aof持久化方式
    # appendfsync always   #每次收到写命令就立即强制写入磁盘，最慢的，但是保证完全的持久化，不推荐使用
    appendfsync everysec #每秒钟强制写入磁盘一次，在性能和持久化方面做了很好的折中，推荐
    # appendfsync no#完全依赖os，性能最好,持久化没保证
aof 的方式也同时带来了另一个问题。持久化文件会变的越来越大。例如我们调用incr test命令100次，文件中必须保存全部的100条命令，其实有99条都是多余的。因为要恢复数据库的状态其实文件中保存一条set  test 100就够了。为了压缩aof的持久化文件。redis提供了bgrewriteaof命令。收到此命令redis将使用与快照类似的方式将内存中的数据以命令的方式保存到临时文件中，最后替换原来的文件。具体过程如下：

​       \1.  redis调用fork ，现在有父子两个进程
​       \2. 子进程根据内存中的数据库快照，往临时文件中写入重建数据库状态的命令
​       \3. 父进程继续处理client请求，除了把写命令写入到原来的aof文件中。同时把收到的写命令缓存起来。这样就能保证如果子进程重写失败的话并不会出问题。
​       \4. 当子进程把快照内容写入已命令方式写到临时文件中后，子进程发信号通知父进程。然后父进程把缓存的写命令也写入到临时文件。
​       \5. 现在父进程可以使用临时文件替换老的aof文件，并重命名，后面收到的写命令也开始往新的aof文件中追加。

​       需要注意到是重写aof文件的操作，并没有读取旧的aof文件，而是将整个内存中的数据库内容用命令的方式重写了一个新的aof文件，这点和快照有点类似。

 

### **（三）虚拟内存方式（desprecated）**

首先说明：在Redis-2.4后虚拟内存功能已经被deprecated了，原因如下：

1）slow restart重启太慢

2）slow saving保存数据太慢

3）slow replication上面两条导致 replication 太慢

4）complex code代码过于复杂

下面还是介绍一下redis的虚拟内存。

redis的虚拟内存与os的虚拟内存不是一码事，但是思路和目的都是相同的。就是暂时把不经常访问的数据从内存交换到磁盘中，从而腾出宝贵的内存空间用于其他需要访问的数据。尤其是对于redis这样的内存数据库，内存总是不够用的。除了可以将数据分割到多个redis  server外。另外的能够提高数据库容量的办法就是使用vm把那些不经常访问的数据交换的磁盘上。如果我们的存储的数据总是有少部分数据被经常访问，大部分数据很少被访问，对于网站来说确实总是只有少量用户经常活跃。当少量数据被经常访问时，使用vm不但能提高单台redis  server数据库的容量，而且也不会对性能造成太多影响。

​        redis没有使用os提供的虚拟内存机制而是自己在用户态实现了自己的虚拟内存机制,作者在自己的blog专门解释了其中原因。

http://antirez.com/post/redis-virtual-memory-story.html
主要的理由有两点：
       \1. os 的虚拟内存是已4k页面为最小单位进行交换的。而redis的大多数对象都远小于4k，所以一个os页面上可能有多个redis对象。另外redis的集合对象类型如list,set可能存在与多个os页面上。最终可能造成只有10%key被经常访问，但是所有os页面都会被os认为是活跃的，这样只有内存真正耗尽时os才会交换页面。
       2.相比于os的交换方式。redis可以将被交换到磁盘的对象进行压缩,保存到磁盘的对象可以去除指针和对象元数据信息。一般压缩后的对象会比内存中的对象小10倍。这样redis的vm会比os  vm能少做很多io操作。

​       下面是vm相关配置：

    slaveof 192.168.1.1 6379  #指定master的ip和端口
    
    vm-enabled yes  #开启vm功能
    vm-swap-file /tmp/redis.swap   #交换出来的value保存的文件路径/tmp/redis.swap
    vm-max-memory 1000000  #redis使用的最大内存上限，超过上限后redis开始交换value到磁盘文件中
    vm-page-size 32#每个页面的大小32个字节
    vm-pages 134217728 #最多使用在文件中使用多少页面,交换文件的大小 = vm-page-size * vm-pages
    vm-max-threads 4   #用于执行value对象换入换出的工作线程数量，0表示不使用工作线程（后面介绍) 
​       redis的vm在设计上为了保证key的查找速度，只会将value交换到swap文件中。所以如果是内存问题是由于太多value很小的key造成的，那么vm并不能解决。和os一样redis也是按页面来交换对象的。redis规定同一个页面只能保存一个对象。但是一个对象可以保存在多个页面中。

在redis使用的内存没超过vm-max-memory之前是不会交换任何value的。当超过最大内存限制后，redis会选择较老的对象。如果两个对象一样老会优先交换比较大的对象，精确的公式swappability  = age*log(size_in_memory)。对于vm-page-size的设置应该根据自己的应用将页面的大小设置为可以容纳大多数对象的大小。太大了会浪费磁盘空间，太小了会造成交换文件出现碎片。对于交换文件中的每个页面，redis会在内存中对应一个1bit值来记录页面的空闲状态。所以像上面配置中页面数量(vm-pages  134217728 )会占用16M内存用来记录页面空闲状态。vm-max-threads表示用做交换任务的线程数量。如果大于0推荐设为服务器的cpu  core的数量。如果是0则交换过程在主线程进行。

参数配置讨论完后，在来简单介绍下vm是如何工作的：
**当vm-max-threads设为0时(Blocking VM)**

**换出：**
       主线程定期检查发现内存超出最大上限后，会直接已阻塞的方式,将选中的对象保存到swap文件中，并释放对象占用的内存,此过程会一直重复直到下面条件满足
       1.内存使用降到最大限制以下
       2.swap文件满了
       3.几乎全部的对象都被交换到磁盘了
**换入：**
              当有client请求value被换出的key时。主线程会以阻塞的方式从文件中加载对应的value对象，加载时此时会阻塞所有client。然后处理client的请求

**当vm-max-threads大于0(Threaded VM)**
**换出：**
       当主线程检测到使用内存超过最大上限，会将选中的要交换的对象信息放到一个队列中交由工作线程后台处理，主线程会继续处理client请求。
**换入：**
       如果有client请求的key被换出了，主线程先阻塞发出命令的client,然后将加载对象的信息放到一个队列中，让工作线程去加载。加载完毕后工作线程通知主线程。主线程再执行client的命令。这种方式只阻塞请求value被换出key的client

​        总的来说blocking vm的方式总的性能会好一些，因为不需要线程同步，创建线程和恢复被阻塞的client等开销。但是也相应的牺牲了响应性。threaded vm的方式主线程不会阻塞在磁盘io上，所以响应性更好。如果我们的应用不太经常发生换入换出，而且也不太在意有点延迟的话则推荐使用blocking  vm的方式。

关于redis vm的更详细介绍可以参考下面链接：
       http://antirez.com/post/redis-virtual-memory-story.html
       http://redis.io/topics/internals-vm

 

**（四）diskstore****方式**

diskstore方式是作者放弃了虚拟内存方式后选择的一种新的实现方式，也就是传统的B-tree的方式。具体细节是：

1) 读操作，使用read through以及LRU方式。内存中不存在的数据从磁盘拉取并放入内存，内存中放不下的数据采用LRU淘汰。

2) 写操作，采用另外spawn一个线程单独处理，写线程通常是异步的，当然也可以把cache-flush-delay配置设成0，Redis尽量保证即时写入。但是在很多场合延迟写会有更好的性能，比如一些计数器用Redis存储，在短时间如果某个计数反复被修改，Redis只需要将最终的结果写入磁盘。这种做法作者叫per  key persistence。由于写入会按key合并，因此和snapshot还是有差异，disk store并不能保证时间一致性。

由于写操作是单线程，即使cache-flush-delay设成0，多个client同时写则需要排队等待，如果队列容量超过cache-max-memory Redis设计会进入等待状态，造成调用方卡住。

Google Group上有热心网友迅速完成了压力[测试](http://lib.csdn.net/base/softwaretest)，当内存用完之后，set每秒处理速度从25k下降到10k再到后来几乎卡住。  虽然通过增加cache-flush-delay可以提高相同key重复写入性能；通过增加cache-max-memory可以应对临时峰值写入。但是diskstore写入瓶颈最终还是在IO。

3) rdb 和新 diskstore 格式关系
rdb是传统Redis内存方式的存储格式，diskstore是另外一种格式，那两者关系如何？

·         通过BGSAVE可以随时将diskstore格式另存为rdb格式，而且rdb格式还用于Redis复制以及不同存储方式之间的中间格式。

·         通过工具可以将rdb格式转换成diskstore格式。

当然，diskstore原理很美好，但是目前还处于alpha版本，也只是一个简单demo，diskstore.c加上注释只有300行，实现的方法就是将每个value作为一个独立文件保存，文件名是key的hash值。因此diskstore需要将来有一个更高效稳定的实现才能用于生产环境。但由于有清晰的接口设计，diskstore.c也很容易换成一种B-Tree的实现。很多开发者也在积极探讨使用bdb或者innodb来替换默认diskstore.c的可行性。

 

下面介绍一下Diskstore的[算法](http://lib.csdn.net/base/datastructure)。

其实DiskStore类似于Hash算法，首先通过SHA1算法把Key转化成一个40个字符的Hash值，然后把Hash值的前两位作为一级目录，然后把Hash值的三四位作为二级目录，最后把Hash值作为文件名，类似于“/0b/ee/0beec7b5ea3f0fdbc95d0dd47f3c5bc275da8a33”形式。算法如下：

dsKeyToPath(key):

char path[1024];

char *hashKey = sha1(key);

path[0] = hashKey[0];

path[1] = hashKey[1];

path[2] = '/';

path[3] = hashKey[2];

path[4] = hashKey[3];

path[5] = '/';

memcpy(path + 6, hashKey, 40);

return path;

 

存储算法（如key == apple）：

dsSet(key, value, expireTime):

​    // d0be2dc421be4fcd0172e5afceea3970e2f3d940

char *hashKey = sha1(key);

 

// d0/be/d0be2dc421be4fcd0172e5afceea3970e2f3d940

char *path = dsKeyToPath(hashKey);

FILE *fp = fopen(path, "w");

rdbSaveKeyValuePair(fp, key, value, expireTime);

fclose(fp)

 

获取算法：

dsGet(key):

char *hashKey = sha1(key);

char *path = dsKeyToPath(hashKey);

FILE *fp = fopen(path, "r");

robj *val = rdbLoadObject(fp);

return val;

 

不过DiskStore有个缺点，就是有可能发生两个不同的Key生成一个相同的SHA1 Hash值，这样就有可能出现丢失数据的问题。不过这种情况发生的几率比较少，所以是可以接受的。根据作者的意图，未来可能使用B+tree来替换这种高度依赖文件系统的实现方法。

##  6、Redis的缓存失效策略

　　本文对Redis的过期机制简单的讲解一下
　　讲解之前我们先抛出一个问题，我们知道很多时候服务器经常会用到redis作为缓存，有很多数据都是临时缓存一下，可能用过之后很久都不会再用到了（比如暂存session，又或者只存放日行情股票数据）那么就会出现一下几个问题了

1. Redis会自己回收清理不用的数据吗？
2. 如果能，那如何配置？
3. 如果不能，如何防止数据累加后大量占用存储空间的问题？

　　之前一直接触Redis不是很深入，最近项目当中遇到一个需求场景，需要清空一些存放在Redis的数据，主要是通过一些时间进行过滤，删除那些不满足的数据，但是这样的工作每天都需要进行，那工作量就比较大了，而且每天都需要按时去手动清理，这样做也不切实际，后面发现Redis中有个设置时间过期的功能，即对存储在Redis数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。这就是我们本文要讲到的Redis过期机制。其实这个机制运用的场景十分广泛，比如我们一般项目中的token或者一些登录信息，尤其是短信验证码都是有时间限制的，或者是限制请求次数，如果按照传统的数据库处理方式，一般都是自己判断过期，这样无疑会严重影响项目性能。

### 一、设置过期时间

　　Redis对存储值的过期处理实际上是针对该值的键（key）处理的，即时间的设置也是设置key的有效时间。Expires字典保存了所有键的过期时间，Expires也被称为过期字段。

- expire key time(以秒为单位)--这是最常用的方式
- setex(String key, int seconds, String value)--字符串独有的方式

注：
　　1、除了字符串自己独有设置过期时间的方法外，其他方法都需要依靠expire方法来设置时间
　　2、如果没有设置时间，那缓存就是永不过期
　　3、如果设置了过期时间，之后又想让缓存永不过期，使用persist key

#### 1、常用方式

一般主要包括4种处理过期方，其中expire都是以秒为单位，pexpire都是以毫秒为单位的。

```
1 EXPIRE key seconds　　//将key的生存时间设置为ttl秒
2 PEXPIRE key milliseconds　　//将key的生成时间设置为ttl毫秒
3 EXPIREAT key timestamp　　//将key的过期时间设置为timestamp所代表的的秒数的时间戳
4 PEXPIREAT key milliseconds-timestamp　　//将key的过期时间设置为timestamp所代表的的毫秒数的时间戳
```

备注：timestamp为unix时间戳（例如：timestamp=1499788800 表示将在2017.07.12过期）
1、2两种方式是设置一个过期的时间段，就是咱们处理验证码最常用的策略，设置三分钟或五分钟后失效，把分钟数转换成秒或毫秒存储到Redis中。 
3、4两种方式是指定一个过期的时间 ，比如优惠券的过期时间是某年某月某日，只是单位不一样。

下面我们就以EXPIREAT为例子简单讲解下用法。

**返回值**

一个整数值1或0，如下：

- 如果成功地为该键设置了超时时间，返回 1
- 如果键不存在或无法设置超时时间，返回 0

**语法**
以下是以Redis的EXPIREAT命令的基本语法。

```
1 redis 127.0.0.1:6379> Expireat KEY_NAME TIME_IN_UNIX_TIMESTAMP
```

**示例**

首先，在Redis中创建一个键：`akey`，并在`akey`中设置一些值。

```
1 redis 127.0.0.1:6379> SET akey redis 
2 OK
```

现在，为设置创建的键设置超时时间为60 秒。

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

```
 1 127.0.0.1:6379> SET akey redis
 2 OK
 3 127.0.0.1:6379> EXPIREAT akey 1393840000
 4 (integer) 1
 5 127.0.0.1:6379> EXISTS akey
 6 (integer) 0
 7 127.0.0.1:6379> SET akey redis
 8 OK
 9 127.0.0.1:6379> EXPIREAT akey 1493840000
10 (integer) 1
11 127.0.0.1:6379> EXISTS akey
12 (integer) 1
```

[![复制代码](https://common.cnblogs.com/images/copycode.gif)](javascript:void(0);)

![img](https://images2017.cnblogs.com/blog/506829/201709/506829-20170927215838653-1475003989.png)

其他三个用法类似，这里不逐一阐述

#### 2、字符串独有方式

对字符串特殊处理的方式为SETEX命令，SETEX命令为指定的 key 设置值及其过期时间。如果 key 已经存在， SETEX 命令将会替换旧的值。

**返回值**

设置成功时返回 OK 。

**语法**

Redis Setex 命令基本语法如下：

```
redis 127.0.0.1:6379> SETEX KEY_NAME TIMEOUT VALUE
```

**示例**

```
1 redis 127.0.0.1:6379> SETEX mykey 60 redis
2 OK
3 redis 127.0.0.1:6379> TTL mykey
4 60
5 redis 127.0.0.1:6379> GET mykey
6 "redis
```

### 二、3种过期策略

- 定时删除
  - 含义：在设置key的过期时间的同时，为该key创建一个定时器，让定时器在key的过期时间来临时，对key进行删除
  - 优点：保证内存被尽快释放
  - 缺点： 
    - 若过期key很多，删除这些key会占用很多的CPU时间，在CPU时间紧张的情况下，CPU不能把所有的时间用来做要紧的事儿，还需要去花时间删除这些key
    - 定时器的创建耗时，若为每一个设置过期时间的key创建一个定时器（将会有大量的定时器产生），性能影响严重
    - 没人用
- **惰性删除**
  - 含义：key过期的时候不删除，每次从数据库获取key的时候去检查是否过期，若过期，则删除，返回null。
  - 优点：删除操作只发生在从数据库取出key的时候发生，而且只删除当前key，所以对CPU时间的占用是比较少的，而且此时的删除是已经到了非做不可的地步（如果此时还不删除的话，我们就会获取到了已经过期的key了）
  - 缺点：若大量的key在超出超时时间后，很久一段时间内，都没有被获取过，那么可能发生内存泄露（无用的垃圾占用了大量的内存）
- **定期删除**
  - 含义：每隔一段时间执行一次删除(在redis.conf配置文件设置hz，1s刷新的频率)过期key操作
  - 优点： 
    - 通过限制删除操作的时长和频率，来减少删除操作对CPU时间的占用--处理"定时删除"的缺点
    - 定期删除过期key--处理"惰性删除"的缺点
  - 缺点 
    - 在内存友好方面，不如"定时删除"
    - 在CPU时间友好方面，不如"惰性删除"
  - 难点 
    - 合理设置删除操作的执行时长（每次删除执行多长时间）和执行频率（每隔多长时间做一次删除）（这个要根据服务器运行情况来定了）

看完上面三种策略后可以得出以下结论： 
定时删除和定期删除为主动删除：Redis会定期主动淘汰一批已过去的key

惰性删除为被动删除：用到的时候才会去检验key是不是已过期，过期就删除

惰性删除为redis服务器内置策略

定期删除可以通过：

- 第一、配置redis.conf 的hz选项，默认为10 （即1秒执行10次，100ms一次，值越大说明刷新频率越快，最Redis性能损耗也越大） 
- 第二、配置redis.conf的maxmemory最大值，当已用内存超过maxmemory限定时，就会触发主动清理策略

 **注意：**

- 上边所说的数据库指的是内存数据库，默认情况下每一台redis服务器有16个数据库（关于数据库的设置，看下边代码），默认使用0号数据库，所有的操作都是对0号数据库的操作，关于redis数据库的存储结构，查看 第八章 Redis数据库结构与读写原理

```
# 设置数据库数量。默认为16个库，默认使用DB 0，可以使用"select 1"来选择一号数据库
# 注意：由于默认使用0号数据库，那么我们所做的所有的缓存操作都存在0号数据库上，
# 当你在1号数据库上去查找的时候，就查不到之前set过得缓存
# 若想将0号数据库上的缓存移动到1号数据库，可以使用"move key 1"
databases 16
```

- memcached只是用了惰性删除，而Redis同时使用了惰性删除与定期删除，这也是二者的一个不同点（可以看做是redis优于memcached的一点）
- 对于惰性删除而言，并不是只有获取key的时候才会检查key是否过期，在某些设置key的方法上也会检查（eg.setnx  key2  value2：该方法类似于memcached的add方法，如果设置的key2已经存在，那么该方法返回false，什么都不做；如果设置的key2不存在，那么该方法设置缓存key2-value2。假设调用此方法的时候，发现redis中已经存在了key2，但是该key2已经过期了，如果此时不执行删除操作的话，setnx方法将会直接返回false，也就是说此时并没有重新设置key2-value2成功，所以对于一定要在setnx执行之前，对key2进行过期检查）

### 三、Redis采用的过期策略

惰性删除+定期删除

- 惰性删除流程 
  - 在进行get或setnx等操作时，先检查key是否过期，
  - 若过期，删除key，然后执行相应操作；
  - 若没过期，直接执行相应操作
- 定期删除流程（简单而言，对指定个数个库的每一个库随机删除小于等于指定个数个过期key） 
  - 遍历每个数据库（就是redis.conf中配置的"database"数量，默认为16） 
    - 检查当前库中的指定个数个key（默认是每个库检查20个key，注意相当于该循环执行20次，循环体时下边的描述） 
      - 如果当前库中没有一个key设置了过期时间，直接执行下一个库的遍历
      - 随机获取一个设置了过期时间的key，检查该key是否过期，如果过期，删除key
      - 判断定期删除操作是否已经达到指定时长，若已经达到，直接退出定期删除。

### 四、**RDB对过期key的处理**

过期key对RDB没有任何影响

- 从内存数据库持久化数据到RDB文件 
  - 持久化key之前，会检查是否过期，过期的key不进入RDB文件
- 从RDB文件恢复数据到内存数据库 
  - 数据载入数据库之前，会对key先进行过期检查，如果过期，不导入数据库（主库情况）

### 五、**AOF对过期key的处理**

过期key对AOF没有任何影响

- 从内存数据库持久化数据到AOF文件： 
  - 当key过期后，还没有被删除，此时进行执行持久化操作（该key是不会进入aof文件的，因为没有发生修改命令）
  - 当key过期后，在发生删除操作时，程序会向aof文件追加一条del命令（在将来的以aof文件恢复数据的时候该过期的键就会被删掉）
- AOF重写 
  - 重写时，会先判断key是否过期，已过期的key不会重写到aof文件 



##  7、Redis集群，高可用，原理

redis 集群模式的工作原理能说一下么？在集群模式下，redis 的 key 是如何寻址的？分布式寻址都有哪些算法？了解一致性 hash 算法吗？

### 面试官心理分析

在前几年，redis 如果要搞几个节点，每个节点存储一部分的数据，得**借助一些中间件**来实现，比如说有 `codis`，或者 `twemproxy`，都有。有一些 redis 中间件，你读写 redis 中间件，redis 中间件负责将你的数据分布式存储在多台机器上的 redis 实例中。

这两年，redis 不断在发展，redis 也不断的有新的版本，现在的 redis 集群模式，可以做到在多台机器上，部署多个 redis  实例，每个实例存储一部分的数据，同时每个 redis 实例可以挂 redis 从实例，自动确保说，如果 redis 主实例挂了，会自动切换到  redis 从实例顶上来。

现在 redis 的新版本，大家都是用 redis cluster 的，也就是 redis 原生支持的 redis  集群模式，那么面试官肯定会就 redis cluster 对你来个几连炮。要是你没用过 redis cluster，正常，以前很多人用  codis 之类的客户端来支持集群，但是起码你得研究一下 redis cluster 吧。

如果你的数据量很少，主要是承载高并发高性能的场景，比如你的缓存一般就几个 G，单机就足够了，可以使用 replication，一个  master 多个 slaves，要几个 slave 跟你要求的读吞吐量有关，然后自己搭建一个 sentinel 集群去保证 redis  主从架构的高可用性。

redis cluster，主要是针对**海量数据+高并发+高可用**的场景。redis cluster 支撑 N  个 redis master node，每个 master node 都可以挂载多个 slave node。这样整个 redis  就可以横向扩容了。如果你要支撑更大数据量的缓存，那就横向扩容更多的 master 节点，每个 master 节点就能存放更多的数据了。



### redis cluster 介绍

- 自动将数据进行分片，每个 master 上放一部分数据
- 提供内置的高可用支持，部分 master 不可用时，还是可以继续工作的

在 redis cluster 架构下，每个 redis 要放开两个端口号，比如一个是 6379，另外一个就是 加1w 的端口号，比如 16379。

16379 端口号是用来进行节点间通信的，也就是 cluster bus 的东西，cluster bus 的通信，用来进行故障检测、配置更新、故障转移授权。cluster bus 用了另外一种二进制的协议，`gossip` 协议，用于节点间进行高效的数据交换，占用更少的网络带宽和处理时间。

#### 节点间的内部通信机制

##### 基本通信原理

- redis cluster 节点间采用 gossip 协议进行通信 集中式是将集群元数据（节点信息、故障等等）几种存储在某个节点上。集中式元数据集中存储的一个典型代表，就是大数据领域的 `storm`。它是分布式的大数据实时计算引擎，是集中式的元数据存储的结构，底层基于 zookeeper（分布式协调的中间件）对所有元数据进行存储维护。

![zookeeper-centralized-storage](https://www.javazhiyin.com/wp-content/uploads/2018/12/zookeeper-centralized-storage.png)

redis 维护集群元数据采用另一个方式， `gossip` 协议，所有节点都持有一份元数据，不同的节点如果出现了元数据的变更，就不断将元数据发送给其它的节点，让其它节点也进行元数据的变更。

![redis-gossip](https://www.javazhiyin.com/wp-content/uploads/2018/12/redis-gossip.png)

**集中式**的**好处**在于，元数据的读取和更新，时效性非常好，一旦元数据出现了变更，就立即更新到集中式的存储中，其它节点读取的时候就可以感知到；**不好**在于，所有的元数据的更新压力全部集中在一个地方，可能会导致元数据的存储有压力。

gossip 好处在于，元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，降低了压力；不好在于，元数据的更新有延时，可能导致集群中的一些操作会有一些滞后。

- 10000 端口 每个节点都有一个专门用于节点间通信的端口，就是自己提供服务的端口号+10000，比如 7001，那么用于节点间通信的就是 17001 端口。每个节点每隔一段时间都会往另外几个节点发送 `ping` 消息，同时其它几个节点接收到 `ping` 之后返回 `pong`。
- 交换的信息 信息包括故障信息，节点的增加和删除，hash slot 信息 等等。

##### gossip 协议

gossip 协议包含多种消息，包含 `ping`,`pong`,`meet`,`fail` 等等。

- meet：某个节点发送 meet 给新加入的节点，让新节点加入集群中，然后新节点就会开始与其它节点进行通信。

```
redis-trib.rb add-node
```

其实内部就是发送了一个 gossip meet 消息给新加入的节点，通知那个节点去加入我们的集群。

- ping：每个节点都会频繁给其它节点发送 ping，其中包含自己的状态还有自己维护的集群元数据，互相通过 ping 交换元数据。
- pong：返回 ping 和 meeet，包含自己的状态和其它信息，也用于信息广播和更新。
- fail：某个节点判断另一个节点 fail 之后，就发送 fail 给其它节点，通知其它节点说，某个节点宕机啦。

##### ping 消息深入

ping 时要携带一些元数据，如果很频繁，可能会加重网络负担。

每个节点每秒会执行 10 次 ping，每次会选择 5 个最久没有通信的其它节点。当然如果发现某个节点通信延时达到了 `cluster_node_timeout / 2`，那么立即发送 ping，避免数据交换延时过长，落后的时间太长了。比如说，两个节点之间都 10 分钟没有交换数据了，那么整个集群处于严重的元数据不一致的情况，就会有问题。所以 `cluster_node_timeout` 可以调节，如果调得比较大，那么会降低 ping 的频率。

每次 ping，会带上自己节点的信息，还有就是带上 1/10 其它节点的信息，发送出去，进行交换。至少包含 `3` 个其它节点的信息，最多包含`总结点-2` 个其它节点的信息。

#### 分布式寻址算法

- hash 算法（大量缓存重建）
- 一致性 hash 算法（自动缓存迁移）+ 虚拟节点（自动负载均衡）
- redis cluster 的 hash slot 算法

##### hash 算法

来了一个 key，首先计算 hash 值，然后对节点数取模。然后打在不同的 master 节点上。一旦某一个 master 节点宕机，所有请求过来，都会基于最新的剩余 master 节点数去取模，尝试去取数据。这会导致**大部分的请求过来，全部无法拿到有效的缓存**，导致大量的流量涌入数据库。

![hash](https://www.javazhiyin.com/wp-content/uploads/2018/12/hash.png)

##### 一致性 hash 算法

一致性 hash 算法将整个 hash 值空间组织成一个虚拟的圆环，整个空间按顺时针方向组织，下一步将各个 master 节点（使用服务器的 ip 或主机名）进行 hash。这样就能确定每个节点在其哈希环上的位置。

来了一个 key，首先计算 hash 值，并确定此数据在环上的位置，从此位置沿环**顺时针“行走”**，遇到的第一个 master 节点就是 key 所在位置。

在一致性哈希算法中，如果一个节点挂了，受影响的数据仅仅是此节点到环空间前一个节点（沿着逆时针方向行走遇到的第一个节点）之间的数据，其它不受影响。增加一个节点也同理。

燃鹅，一致性哈希算法在节点太少时，容易因为节点分布不均匀而造成**缓存热点**的问题。为了解决这种热点问题，一致性 hash 算法引入了虚拟节点机制，即对每一个节点计算多个 hash，每个计算结果位置都放置一个虚拟节点。这样就实现了数据的均匀分布，负载均衡。

![consistent-hashing-algorithm](https://www.javazhiyin.com/wp-content/uploads/2018/12/consistent-hashing-algorithm.png)

##### redis cluster 的 hash slot 算法

redis cluster 有固定的 `16384` 个 hash slot，对每个 `key` 计算 `CRC16` 值，然后对 `16384` 取模，可以获取 key 对应的 hash slot。

redis cluster 中每个 master 都会持有部分 slot，比如有 3 个 master，那么可能每个 master 持有  5000 多个 hash slot。hash slot 让 node 的增加和移除很简单，增加一个 master，就将其他 master 的  hash slot 移动部分过去，减少一个 master，就将它的 hash slot 移动到其他 master 上去。移动 hash slot  的成本是非常低的。客户端的 api，可以对指定的数据，让他们走同一个 hash slot，通过 `hash tag` 来实现。

任何一台机器宕机，另外两个节点，不影响的。因为 key 找的是 hash slot，不是机器。

![hash-slot](https://www.javazhiyin.com/wp-content/uploads/2018/12/hash-slot.png)

#### redis cluster 的高可用与主备切换原理

redis cluster 的高可用的原理，几乎跟哨兵是类似的

##### 判断节点宕机

如果一个节点认为另外一个节点宕机，那么就是 `pfail`，**主观宕机**。如果多个节点都认为另外一个节点宕机了，那么就是 `fail`，**客观宕机**，跟哨兵的原理几乎一样，sdown，odown。

在 `cluster-node-timeout` 内，某个节点一直没有返回 `pong`，那么就被认为 `pfail`。

如果一个节点认为某个节点 `pfail` 了，那么会在 `gossip ping` 消息中，`ping` 给其他节点，如果**超过半数**的节点都认为 `pfail` 了，那么就会变成 `fail`。

##### 从节点过滤

对宕机的 master node，从其所有的 slave node 中，选择一个切换成 master node。

检查每个 slave node 与 master node 断开连接的时间，如果超过了 `cluster-node-timeout * cluster-slave-validity-factor`，那么就**没有资格**切换成 `master`。

##### 从节点选举

每个从节点，都根据自己对 master 复制数据的 offset，来设置一个选举时间，offset 越大（复制数据越多）的从节点，选举时间越靠前，优先进行选举。

所有的 master node 开始 slave 选举投票，给要进行选举的 slave 进行投票，如果大部分 master node`（N/2 + 1）`都投票给了某个从节点，那么选举通过，那个从节点可以切换成 master。

从节点执行主备切换，从节点切换为主节点。

##### 与哨兵比较

整个流程跟哨兵相比，非常类似，所以说，redis cluster 功能强大，直接集成了 replication 和 sentinel 的功能。

##  8、Redis缓存分片

​     Redis的分片（Sharding或者Partitioning）技术是指将数据分散到多个Redis实例中的方法，分片之后，每个redis拥有一部分原数据集的子集。在数据量非常大时，这种技术能够将数据量分散到若干主机的redis实例上，进而减轻单台redis实例的压力。分片技术能够以更易扩展的方式使用多台计算机的存储能力（这里主要指内存的存储能力）和计算能力：

​    （1）从存储能力的角度，分片技术通过使用多台计算机的内存来承担更大量的数据，如果没有分片技术，那么redis的存储能力将受限于单台主机的内存大小。

​    （2） 从计算能力的角度，分片技术通过将计算任务分散到多核或者多台主机中，能够充分利用多核、多台主机的计算能力。

下面将以举例的方式说明分片技术及其存在的优势：

示例1：未采用分片技术，有1000万条用户信息数据，以键值对：UsrID:UsrInfo的形式存储在一个redis实例中，此时所有的用户信息都会存储在一个redis实例中，对这1000万条数据的所有插、查、删、该操作压力都会集中在这个redis所在的主机上；此时所要考虑的问题不仅有存储和操作对该主机的压力，还有该主机失效时将导致所有操作都无法进行的问题。如下图1所示：

![图1 单redis实例](https://img-blog.csdn.net/20140730173159406?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaG91aml4aW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

示例2：采用分片技术；有1000万条用户信息数据，以键值对：UsrID:UsrInfo的形式存储于redis中，此时有4台主机，每台主机运行一个Redis实例：主机A （Redis1）、主机B(Redis2)、主机C(Redis3)、主机D（Redis4），分片时算法为：

redis_index = 用户的ID % 4 + 1;

例如ID为10000654则可得到到redis_index的值：10000654 % 4 + 1 = 1，即用户10000654的信息将被放到Redis1上，所有对用户1000654的操作也将被分片到Redis1上；假如用户ID以顺序方式出现，这1000万条用户信息将被平均分配到这四台主机的各Redis实例上，如下图2所示：


![图2 采用分片算法](https://img-blog.csdn.net/20140730173221843?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvaG91aml4aW4=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

采用分片之后，数据将被分散到4个redis实例中，对数据的操作也被分散到每个redis实例中，此时单台主机的压力将大大减轻。

分片的部署，即实例2中分片算法被放在哪里？是在分片时需要首先考虑的问题，分片部署方式一般分为以下三种：

​     （1）在客户端做分片；这种方式在客户端确定要连接的redis实例，然后直接访问相应的redis实例；

​     （2）在代理中做分片；这种方式中，客户端并不直接访问redis实例，它也不知道自己要访问的具体是哪个redis实例，而是由代理转发请求和结果；其工作过程为：客户端先将请求发送给代理，代理通过分片算法确定要访问的是哪个redis实例，然后将请求发送给相应的redis实例，redis实例将结果返回给代理，代理最后将结果返回给客户端。

​     （3）在redis服务器端做分片；这种方式被称为“查询路由”，在这种方式中客户端随机选择一个redis实例发送请求，如果所请求的内容不再当前redis实例中它会负责将请求转交给正确的redis实例，也有的实现中，redis实例不会转发请求，而是将正确redis的信息发给客户端，由客户端再去向正确的redis实例发送请求。

上面主要描述了分片的优点，当然分片的存在也有缺陷，例如：

​    （1） 通常无法支持涉及多键的操作；在redis中有很多一次操作多个key的操作，例如求集合交集的SINTER操作，该操作将涉及到多个键，而这多个键有可能被分片到不同的redis实例中，此时就无法执行这种操作。

​    （2）Redis的事务操作中涉及多个键时也不能用；

​    （3）分片将导致数据处理更加复杂；例如在分片过程中，随着redis实例的增加，数据备份等操作都将会变得更加复杂。

​     （4）Redis目前不支持动态分片操作，扩容和缩容操作都会比较复杂，尤其分片操作部署在客户端时，需要重新配置和启动客户端。在使用过程中缩容用的不多，扩容可以采用后面介绍的预分片策略来缓解此问题。

### **预分片技术**

在正常运营环境中，一般所存储的数据会逐渐增加，可能今天只要10个redis实例就能应付，但是到了一年以后就需要50个redis实例才能支撑，因此，redis的扩容是经常用到的功能，在redis的分布式部署中，有预分片技术是非常好用的方法之一；

​     预分片技术是指在开始时就启动足够多的redis实例（例如32或64个，估计一下够以后扩展用就行了），等到后续需要扩容的时候，只需要将其中一部分的redis实例转移到新增加的机子上即可，在redis实例迁移过程中使用redis的复制功能可以最大限度的降低redis的停工时间甚至可以做到没有停工时间。由于redis实例是轻量级的进程，而且占用内存较少，这里指单纯的空的redis实例，一个空的redis实例大约占用1M的内存；因此，这种方式即不会占用太多系统开销，又便于实现；

​     Redis的预分片技术可以按照以下步骤进行实例迁移操作：

​    （1）在新机子上启动新的redis实例；

​    （2）将新redis实例作为slave将原redis实例作为master，将数据从原redis实例迁移到新redis实例上；

​    （3）停止客户端（分片操作在客户端上时）或代理服务器（分片操作在代理上）

​    （4）更新客户端或者代理服务器中的配置信息，去掉被迁移的原redis实例的ip和端口等信息，加上新启动redis实例的IP地址和端口；

​    （5）向新启动的redis发送SLAVEOF NOONE命令，终止新redis实例对原redis实例的从属关系；

​    （6）重启客户端程序或者代理程序，此时它们将会使用新的redis实例；

​    （7）关掉被迁移走数据的原redis实例；



##  9、Redis的数据淘汰策略

## 简介

redis可以通过`maxmemory <bytes>`配置项来设置允许用户使用的最大内存大小，当内存数据集大小达到一定的大小时，就会根据`maxmemory-policy noeviction`配置项配置的策略来进行数据淘汰。

redis提供了6种数据淘汰策略：

- volatile-lru

  > 从已设置过期时间的数据集（server.db[i].expires）中挑选最近最少使用的数据淘汰

- allkeys-lru

  > 从数据集（server.db[i].dict）中挑选最近最少使用的数据淘汰

- volatile-random

  > 从已设置过期时间的数据集（server.db[i].expires）中任意选择数据淘汰

- allkeys-random

  > 从数据集（server.db[i].dict）中任意选择数据淘汰

- volatile-ttl

  > 从已设置过期时间的数据集（server.db[i].expires）中挑选将要过期的数据淘汰

- noeviction

  > 禁止驱逐数据，永远不过期，仅对写操作返回一个错误，默认为该项

##  

## 淘汰机制

在服务器配置中保存了lru计数器lrulock，会通过定时程序serverCorn()进行定时更新

```
struct redisServer {
    /* General */
    pid_t pid;                  /* Main process pid. */
    char *configfile;           /* Absolute config file path, or NULL */
    int hz;                     /* serverCron() calls frequency in hertz */
    redisDb *db;
    dict *commands;             /* Command table */
    dict *orig_commands;        /* Command table before command renaming. */
    aeEventLoop *el;
    unsigned lruclock:REDIS_LRU_BITS; /* Clock for LRU eviction */
    ......
}
```

而在redisobject中都会为每个redis对象设置相应的lru，即最近访问时间，每次访问的时候都会更新redisObject.lru。

```
/* A redis object, that is a type able to hold a string / list / set */

/* The actual Redis Object */
#define REDIS_LRU_BITS 24
#define REDIS_LRU_CLOCK_MAX ((1<<REDIS_LRU_BITS)-1) /* Max value of obj->lru */
#define REDIS_LRU_CLOCK_RESOLUTION 1000 /* LRU clock resolution in ms */
typedef struct redisObject {
    unsigned type:4;
    unsigned encoding:4;
    unsigned lru:REDIS_LRU_BITS; /* lru time (relative to server.lruclock) */
    int refcount;
    void *ptr;
} robj;
```

而redisDb中有保存所有键的哈希表和保存键过期时间哈希表，如下所示

```
/* Redis database representation. There are multiple databases identified
 * by integers from 0 (the default database) up to the max configured
 * database. The database number is the 'id' field in the structure. */
typedef struct redisDb {
    dict *dict;                 /* The keyspace for this DB */
    dict *expires;              /* Timeout of keys with a timeout set */
    dict *blocking_keys;        /* Keys with clients waiting for data (BLPOP) */
    dict *ready_keys;           /* Blocked keys that received a PUSH */
    dict *watched_keys;         /* WATCHED keys for MULTI/EXEC CAS */
    struct evictionPoolEntry *eviction_pool;    /* Eviction pool of keys */
    int id;                     /* Database ID */
    long long avg_ttl;          /* Average TTL, just for stats */
} redisDb;
```

###  

### LRU数据淘汰机制

该淘汰机制是这样的：在数据集中随机挑选几个键值对，取出其中lru最大的键值对进行淘汰。

Redis 并不是保证取得所有数据集中最近最少使用（LRU）的键值对，而只是随机挑选的几个键值对中的。

以下是定时任务,每秒调用server.hz次，主要异步做一些相应的操作，例如：

- 激活过期键的收集工作
- 软件监控
- 更新一些统计信息
- 递增重新哈希数据库的哈希表
- 触发BGSAVE/AOF写等持久化操作
- 不同种类的客户端超时
- 复制同步重连接

```
int serverCron(struct aeEventLoop *eventLoop, long long id, void *clientData) {
    int j;
    REDIS_NOTUSED(eventLoop);
    REDIS_NOTUSED(id);
    REDIS_NOTUSED(clientData);

    /* Software watchdog: deliver the SIGALRM that will reach the signal
     * handler if we don't return here fast enough. */
    if (server.watchdog_period) watchdogScheduleSignal(server.watchdog_period);

    /* Update the time cache. */
    updateCachedTime();

    run_with_period(100) {
        trackInstantaneousMetric(REDIS_METRIC_COMMAND,server.stat_numcommands);
        trackInstantaneousMetric(REDIS_METRIC_NET_INPUT,
                server.stat_net_input_bytes);
        trackInstantaneousMetric(REDIS_METRIC_NET_OUTPUT,
                server.stat_net_output_bytes);
    }

    /* We have just REDIS_LRU_BITS bits per object for LRU information.
     * So we use an (eventually wrapping) LRU clock.
     *
     * Note that even if the counter wraps it's not a big problem,
     * everything will still work but some object will appear younger
     * to Redis. However for this to happen a given object should never be
     * touched for all the time needed to the counter to wrap, which is
     * not likely.
     *
     * Note that you can change the resolution altering the
     * REDIS_LRU_CLOCK_RESOLUTION define. */
    server.lruclock = getLRUClock();

    .......

    /* Show some info about non-empty databases */
    run_with_period(5000) {
        for (j = 0; j < server.dbnum; j++) {
            long long size, used, vkeys;

            size = dictSlots(server.db[j].dict);
            used = dictSize(server.db[j].dict);
            vkeys = dictSize(server.db[j].expires);
            if (used || vkeys) {
                redisLog(REDIS_VERBOSE,"DB %d: %lld keys (%lld volatile) in %lld slots HT.",j,used,vkeys,size);
                /* dictPrintStats(server.dict); */
            }
        }
    }

    /* Show information about connected clients */
    if (!server.sentinel_mode) {
        run_with_period(5000) {
            redisLog(REDIS_VERBOSE,
                "%lu clients connected (%lu slaves), %zu bytes in use",
                listLength(server.clients)-listLength(server.slaves),
                listLength(server.slaves),
                zmalloc_used_memory());
        }
    }

    /* We need to do a few operations on clients asynchronously. */
    clientsCron();

    /* Handle background operations on Redis databases. */
    databasesCron();

    .........


    /* Replication cron function -- used to reconnect to master and
     * to detect transfer failures. */
    run_with_period(1000) replicationCron();

    /* Run the Redis Cluster cron. */
    run_with_period(100) {
        if (server.cluster_enabled) clusterCron();
    }

    /* Run the Sentinel timer if we are in sentinel mode. */
    run_with_period(100) {
        if (server.sentinel_mode) sentinelTimer();
    }

    /* Cleanup expired MIGRATE cached sockets. */
    run_with_period(1000) {
        migrateCloseTimedoutSockets();
    }

    server.cronloops++;
    return 1000/server.hz;
}

//更新服务器的lru计数器
unsigned int getLRUClock(void) {
    return (mstime()/REDIS_LRU_CLOCK_RESOLUTION) & REDIS_LRU_CLOCK_MAX;
}
```

###  

### TTL数据淘汰机制

Redis 数据集数据结构中保存了键值对过期时间的表，即 redisDb.expires，在使用 SET  命令的时候，就有一个键值对超时时间的选项。和 LRU 数据淘汰机制类似，TTL 数据淘汰机制是这样的：从过期时间 redisDB.expires  表中随机挑选几个键值对，取出其中 ttl 最大的键值对淘汰。同样你会发现，Redis  并不是保证取得所有过期时间的表中最快过期的键值对，而只是随机挑选的几个键值对中的。

###  

### 数据淘汰过程

redis每次执行一个命令的时候，都会检测使用的内存是否超额，如果超额则进行数据淘汰，即是在执行读写的时间才会进行数据淘汰

processCommand()函数在执行命令的时候会检测内存使用情况，这时会调用freeMemoryIfNeeded()函数来进行淘汰，该函数主要是释放足够的内存来保持redis在其配置内存限制之内，他计算需要释放多少内存，然后进入循环选择最合适的键，如下所示：

```
int freeMemoryIfNeeded(void) {
    size_t mem_used, mem_tofree, mem_freed;
    int slaves = listLength(server.slaves);
    mstime_t latency, eviction_latency;

    /* Remove the size of slaves output buffers and AOF buffer from the
     * count of used memory. */
    //slaves输出缓存与AOF缓存不计算在内
    mem_used = zmalloc_used_memory();
    if (slaves) {
        listIter li;
        listNode *ln;

        listRewind(server.slaves,&li);
        while((ln = listNext(&li))) {
            redisClient *slave = listNodeValue(ln);
            unsigned long obuf_bytes = getClientOutputBufferMemoryUsage(slave);
            if (obuf_bytes > mem_used)
                mem_used = 0;
            else
                mem_used -= obuf_bytes;
        }
    }
    if (server.aof_state != REDIS_AOF_OFF) {
        mem_used -= sdslen(server.aof_buf);
        mem_used -= aofRewriteBufferSize();
    }

    /* Check if we are over the memory limit. */
    //如果已经使用的没有达到上限，则直接返回ok
    if (mem_used <= server.maxmemory) return REDIS_OK;

    if (server.maxmemory_policy == REDIS_MAXMEMORY_NO_EVICTION)
        return REDIS_ERR; /* We need to free memory, but policy forbids. */

    /* Compute how much memory we need to free. */
    //计算需要释放多少内存
    mem_tofree = mem_used - server.maxmemory;
    mem_freed = 0;
    latencyStartMonitor(latency);
    //选择最合适的key释放内存直到达到了需要的内存为止
    while (mem_freed < mem_tofree) {
        int j, k, keys_freed = 0;

        for (j = 0; j < server.dbnum; j++) {
            long bestval = 0; /* just to prevent warning */
            sds bestkey = NULL;
            dictEntry *de;
            redisDb *db = server.db+j;
            dict *dict;

            //判断淘汰策略是否与过期key有关,即从哪个哈希表找相应的key
            if (server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_LRU ||
                server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_RANDOM)
            {
                dict = server.db[j].dict;
            } else {
                dict = server.db[j].expires;
            }
            if (dictSize(dict) == 0) continue;

            /* volatile-random and allkeys-random policy */
            if (server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_RANDOM ||
                server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_RANDOM)
            {
                de = dictGetRandomKey(dict);
                bestkey = dictGetKey(de);
            }

            /* volatile-lru and allkeys-lru policy */
            else if (server.maxmemory_policy == REDIS_MAXMEMORY_ALLKEYS_LRU ||
                server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_LRU)
            {
                struct evictionPoolEntry *pool = db->eviction_pool;

                while(bestkey == NULL) {
                    evictionPoolPopulate(dict, db->dict, db->eviction_pool);
                    /* Go backward from best to worst element to evict. */
                    for (k = REDIS_EVICTION_POOL_SIZE-1; k >= 0; k--) {
                        if (pool[k].key == NULL) continue;
                        de = dictFind(dict,pool[k].key);

                        /* Remove the entry from the pool. */
                        sdsfree(pool[k].key);
                        /* Shift all elements on its right to left. */
                        memmove(pool+k,pool+k+1,
                            sizeof(pool[0])*(REDIS_EVICTION_POOL_SIZE-k-1));
                        /* Clear the element on the right which is empty
                         * since we shifted one position to the left.  */
                        pool[REDIS_EVICTION_POOL_SIZE-1].key = NULL;
                        pool[REDIS_EVICTION_POOL_SIZE-1].idle = 0;

                        /* If the key exists, is our pick. Otherwise it is
                         * a ghost and we need to try the next element. */
                        if (de) {
                            bestkey = dictGetKey(de);
                            break;
                        } else {
                            /* Ghost... */
                            continue;
                        }
                    }
                }
            }

            /* volatile-ttl */
            else if (server.maxmemory_policy == REDIS_MAXMEMORY_VOLATILE_TTL) {
                for (k = 0; k < server.maxmemory_samples; k++) {
                    sds thiskey;
                    long thisval;

                    de = dictGetRandomKey(dict);
                    thiskey = dictGetKey(de);
                    thisval = (long) dictGetVal(de);

                    /* Expire sooner (minor expire unix timestamp) is better
                     * candidate for deletion */
                    if (bestkey == NULL || thisval < bestval) {
                        bestkey = thiskey;
                        bestval = thisval;
                    }
                }
            }

            //最后删除选择的key
            /* Finally remove the selected key. */
            if (bestkey) {
                long long delta;

                robj *keyobj = createStringObject(bestkey,sdslen(bestkey));
                propagateExpire(db,keyobj);
                /* We compute the amount of memory freed by dbDelete() alone.
                 * It is possible that actually the memory needed to propagate
                 * the DEL in AOF and replication link is greater than the one
                 * we are freeing removing the key, but we can't account for
                 * that otherwise we would never exit the loop.
                 *
                 * AOF and Output buffer memory will be freed eventually so
                 * we only care about memory used by the key space. */
                delta = (long long) zmalloc_used_memory();
                latencyStartMonitor(eviction_latency);
                dbDelete(db,keyobj);
                latencyEndMonitor(eviction_latency);
                latencyAddSampleIfNeeded("eviction-del",eviction_latency);
                latencyRemoveNestedEvent(latency,eviction_latency);
                delta -= (long long) zmalloc_used_memory();
                mem_freed += delta;
                server.stat_evictedkeys++;
                notifyKeyspaceEvent(REDIS_NOTIFY_EVICTED, "evicted",
                    keyobj, db->id);
                decrRefCount(keyobj);
                keys_freed++;

                /* When the memory to free starts to be big enough, we may
                 * start spending so much time here that is impossible to
                 * deliver data to the slaves fast enough, so we force the
                 * transmission here inside the loop. */
                if (slaves) flushSlavesOutputBuffers();
            }
        }
        if (!keys_freed) {
            latencyEndMonitor(latency);
            latencyAddSampleIfNeeded("eviction-cycle",latency);
            return REDIS_ERR; /* nothing to free... */
        }
    }
    latencyEndMonitor(latency);
    latencyAddSampleIfNeeded("eviction-cycle",latency);
    return REDIS_OK;
}
```